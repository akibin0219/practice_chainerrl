{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-nashville",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fancy-fruit",
   "metadata": {},
   "source": [
    "# テスト的に一度実際のbotで実装を試してみるノートブック，ごちゃごちゃしそうなので注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eastern-moscow",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\cupy\\_environment.py:399: UserWarning: \n",
      "cudnn library could not be loaded.\n",
      "\n",
      "Reason: ImportError (DLL load failed while importing cudnn: 指定されたモジュールが見つかりません。)\n",
      "\n",
      "You can install the library by:\n",
      "\n",
      "  $ python -m cupyx.tools.install_library --library cudnn --cuda 11.2\n",
      "\n",
      "  warnings.warn(msg)\n",
      "c:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\chainer\\backends\\cuda.py:154: UserWarning: cuDNN is not enabled.\n",
      "Please reinstall CuPy after you install cudnn\n",
      "(see https://docs-cupy.chainer.org/en/stable/install.html#install-cudnn).\n",
      "  warnings.warn(\n",
      "c:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\chainer\\_environment_check.py:72: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "CuPy (cupy-cuda112) version 10.6.0 may not be compatible with this version of Chainer.\n",
      "Please consider installing the supported version by running:\n",
      "  $ pip install 'cupy-cuda112>=7.7.0,<8.0.0'\n",
      "\n",
      "See the following page for more details:\n",
      "  https://docs.cupy.dev/en/latest/install.html\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  warnings.warn(msg.format(\n"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import chainerrl\n",
    "import gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore',  category=pd.errors.PerformanceWarning)#解決できない警告は無視"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-basket",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "japanese-aquatic",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../boatracer_BOT_making/bot_database/asiya/asiya_train/train_asiya.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8ba4ded18189>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mresult_filepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"../boatracer_BOT_making/bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#作成したデータの書き込み先#使用するデータの読み込み\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msample_race_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msample_race_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_race_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Unnamed: 0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msample_race_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    787\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../boatracer_BOT_making/bot_database/asiya/asiya_train/train_asiya.csv'"
     ]
    }
   ],
   "source": [
    "place_name='asiya'\n",
    "\n",
    "result_filepath=\"../boatracer_BOT_making/bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "sample_race_df=pd.read_csv(result_filepath)\n",
    "sample_race_df=sample_race_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "sample_race_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-century",
   "metadata": {},
   "source": [
    "# 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surprising-shaft",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def trans_date_type(df):\n",
    "    df['date']=pd.to_datetime(df['date'])#日付が文字列なのでdateを日付型に変換\n",
    "    #df['year']=df['date'].dt.year\n",
    "    #df=df.drop('date',axis=1)\n",
    "    return df\n",
    "\n",
    "def data_making(df):#クラスタリングなし、ボート、艇番号無し\n",
    "    warnings.simplefilter('ignore',  category=pd.errors.PerformanceWarning)#解決できない警告は無視\n",
    "    result_df=df\n",
    "    result_df=result_df.drop([\"racer_1_ID\",\"racer_2_ID\",\"racer_3_ID\",\"racer_4_ID\",\"racer_5_ID\",\"racer_6_ID\",],axis=1)#IDはいらないので削除\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_ave_st_time\":0.22})#新人のave_st_timeを0.22に\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_doub_win\":0.02})#新人の着に絡む確率ave_st_timeを0.02に(新人の半期の偏差から導出)\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_doub_win\":0.02})\n",
    "    #ダミー変数化\n",
    "    result_df_dummie=result_df\n",
    "    race_dummie_df=pd.get_dummies(result_df_dummie['number_race'])#number_raceをダミー化\n",
    "    for column, val in race_dummie_df.iteritems():\n",
    "        result_df_dummie['race_{}'.format(int(column))]=val\n",
    "    result_df_dummie=result_df_dummie.drop('number_race',axis=1)\n",
    "\n",
    "    cols=list(result_df_dummie.columns)\n",
    "    male_cols=[s for s in cols if 'male' in s]#性別を示すカラムを取り出す\n",
    "\n",
    "    #===========================新規、性別の取り出し機能が良くなかったため作り直す\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in male_cols:\n",
    "        for number in np.arange(0,2,1):\n",
    "              result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        male_dummie_df=pd.get_dummies(result_df_dummie[col])#性別をダミー化\n",
    "        for column, val in male_dummie_df.iteritems():\n",
    "              result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "\n",
    "    cols=list(result_df_dummie.columns)\n",
    "    moter_cols=[s for s in cols if '_mo' in s]#モーター番号を示すカラムを取り出す\n",
    "    boat_cols=[s for s in cols if '_bo' in s]#ボート番号を示すカラムを取り出す\n",
    "    #boat、moterの情報は使わない、\n",
    "    numbers=np.arange(1, 100, 1)\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in moter_cols:\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1).copy()\n",
    "    for col in boat_cols:\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1).copy()\n",
    "    clustar_target_df=result_df_dummie\n",
    "    clustaring_df=clustar_target_df\n",
    "    model_df=clustaring_df\n",
    "    model_df=trans_date_type(model_df)\n",
    "    return model_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-bridal",
   "metadata": {},
   "source": [
    "# boatraceでの環境の定義（cartpoleを参考に）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-acquisition",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 出力を1～28の確率分布とし，それを係数として購買を行う＝確率分布で出力するやり方がわからない，最もらしい行動を一つピックアップされてしまう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "painted-dialogue",
   "metadata": {
    "code_folding": [
     28,
     41,
     107
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BoatraceEnv:\n",
    "#class BoatraceEnv(必要であればここに購買金額の係数等を書いてあげる):\n",
    "    def __init__(self,race_df,cash,bet_coefficient=10000,end_th_cash_magni=0.5):#メンバ等の定義\n",
    "        \n",
    "        self.st_cash = cash#初めに持っている所持金\n",
    "        self.cash = cash#所持金（初めは上のものと同じ値が入るが，こちらの変数はゲームが進んでいくと更新されていく）\n",
    "        self.end_th_cash = cash*end_th_cash_magni#所持金がいくらを下回ったらゲームオーバーか決めるための閾値金額(end_th_cashで何パーセントを下回ったらアウトかを指定)\n",
    "        self.bet_coefficient = bet_coefficient#購買時を想定して定数倍する係数\n",
    "        self.random_state = 7#何かと生成をするときに使うためのシード値\n",
    "        self.race_df=race_df#全部のレース情報のまとめdfを格納\n",
    "        \n",
    "        #self.race_ID=0#どこのレースを抜き出すかどうかの番号付け\n",
    "        self.race_ID=0#どこのレースを抜き出すかどうかの番号付け(インデックス参照で抜き出す)\n",
    "        self.total_gain = None#現時点と開始時を比較した時の利益率(reset()で要リセット)\n",
    "        self.total_use = 0#現時点までの総使用金額(reset()で要リセット)\n",
    "        self.total_get = 0#現時点までの総獲得金額(reset()で要リセット)\n",
    "        self.state = None#1レースあたりのデータ格納用のメンバ\n",
    "        self.steps_beyond_done = None\n",
    "        \n",
    "        #Q関数定義時関連の処理\n",
    "        self.n_action=28#行動の種類(28通りのcomを購買対象とする)\n",
    "        sample_df=self.race_df.copy()\n",
    "        sample_df=sample_df.drop(['date',\"result_com\",\"money\"],axis=1)\n",
    "        self.obs_size=len(sample_df.columns)#予測に使う情報の次元数\n",
    "\n",
    "#     def seed(self, seed=None):\n",
    "#         self.np_random, seed = seeding.np_random(seed)\n",
    "#         return [seed]\n",
    "    def split_race_data(self,race_ID):#レースのID(インデックス)を渡して，レースの情報を学習時などに使いやすい形に切り分けるメソッド\n",
    "        race_row=self.race_df.iloc[race_ID]#対象のレースを切り抜き(series型)\n",
    "        result_com=race_row['result_com']\n",
    "        return_money=race_row['money']\n",
    "        racer_ID=race_row['money']\n",
    "        race_date=race_row['date']\n",
    "        race_data=race_row.drop(['date',\"result_com\",\"money\"]).values\n",
    "        race_data_label=race_row.drop(['date',\"result_com\",\"money\"]).index\n",
    "                                \n",
    "        #race_data:選手情報やボート・モータ番号などの予測用データが入った配列\n",
    "        #race_data_label:予測用データの役割を示す配列(pandasの列名（カラム）がこれに該当する)\n",
    "        return result_com,return_money,race_data,race_data_label,race_date\n",
    "\n",
    "    def step(self, action):#ステップ（ゲームの報酬計算と次の環境の取得）\n",
    "        race_ID=self.race_ID\n",
    "        result_com,return_money,race_data,race_data_label,race_date=self.split_race_data(self.race_ID)#いろいろ算出用にレースデータの抜き取り\n",
    "        return_money_magni=return_money/100#配当金を倍率に変換\n",
    "        #state = self.state\n",
    "                                      \n",
    "        #それに応じて購買行動を行う(1～28で購買を行う)\n",
    "        #インデックス番号＋１が購買を行う番号と対応している（はず）\n",
    "        total_use=sum(action)#使った金額の算出\n",
    "        #total_use=sum(action)*self.bet_coefficient#使った金額の算出\n",
    "        \n",
    "        #当たったかどうかの判別と，リターンの算出\n",
    "        race_use=0\n",
    "        for label,pred in zip(np.arange(1, len(action)+1) ,action):#予測のラベル(com)と購買金額の倍率で一緒にfor分を回す\n",
    "            race_use+=pred\n",
    "            if label==result_com:#ラベルと結果が一致したら\n",
    "                race_get=pred*return_money_magni#return_money_magni:配当の倍率(magnification)\n",
    "                #get=pred*self.bet_coefficient*return_money_magni\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        #収支計算()\n",
    "        #race_gain=(race_get/race_use)#廃止，これだと０除算になる可能性が高い\n",
    "        race_gain=race_get-race_use#割合でなく，実際の金額で計算．（まあ本番も利益額大きい方がうれしいし？？？）\n",
    "        self.total_use+=race_use\n",
    "        self.total_get+=race_get\n",
    "        if (self.total_get!=0) and (self.total_get!=0):\n",
    "            self.total_gain=((self.total_get/self.total_use)*100)-100#利益率を計算(減ってるとマイナスになる)\n",
    "        else:\n",
    "            self.total_gain=0\n",
    "        before_cash=self.cash#購買行動を行う前の所持金を取っておく\n",
    "        self.cash=self.cash-race_use#使用金額を引く\n",
    "        self.cash=self.cash+race_get#配当金を足す\n",
    "        diff_cash=self.cash-before_cash#購買を行う前と後の金額を比較(減ってるとマイナスになる)\n",
    "        \n",
    "        #報酬の決定\n",
    "        reward=diff_cash#前のレースと比べてお金が増えたか減ったかをそのまま報酬とする\n",
    "#         if diff_cash==0:\n",
    "#             reward=-0.1*bet_coefficient#全く購買を行わないのにも罰則を与える\n",
    "        \n",
    "        #各種フラグの付与（ゲームが続くか続かないか）\n",
    "        if self.cash<self.end_th_cash:#所持金が指定金額以上に減ったらゲームオーバー\n",
    "            done=True\n",
    "        else:\n",
    "            done=False\n",
    "            \n",
    "        #次の観測（次のレース）の取り出し\n",
    "        self.race_ID=self.race_ID+1#次の状態を抜き出すためにIDに1を足す\n",
    "        if self.race_ID>(len(self.race_df)-1):#次の状態(レース)がなくなったら終了\n",
    "            done=True\n",
    "            self.state=None\n",
    "            reward=None\n",
    "        else:\n",
    "            result_com_next,return_money_next,race_data_next,race_data_label_next,race_date_next=self.split_race_data(self.race_ID)\n",
    "            \n",
    "        #行動分析用の追加評価値\n",
    "        #total_gain=(self.cash/self.st_cash)*100#現時点での利益率\n",
    "        total_income=self.total_get-self.total_use#獲得とそうでないものの差から，今までの利益額を算出\n",
    "        scores_dict={\n",
    "            'total_gain':self.total_gain ,\n",
    "            'total_income':total_income ,\n",
    "            'total_get':self.total_get ,\n",
    "            'total_use':self.total_use\n",
    "        }\n",
    "        return np.array(race_data_next), reward, done, scores_dict\n",
    "\n",
    "    def reset(self):#環境の初期化用メソッド\n",
    "        self.cash = self.st_cash#スタート時の所持金\n",
    "        self.race_ID=0#どこのレースを抜き出すかどうかの番号付け(インデックス参照で抜き出す)\n",
    "        self.total_gain = None#現時点と開始時を比較した時の利益率(reset()で要リセット)\n",
    "        self.total_use = 0#現時点までの総使用金額(reset()で要リセット)\n",
    "        self.total_get = 0#現時点までの総獲得金額(reset()で要リセット)\n",
    "        self.state = None#1レースあたりのデータ格納用のメンバ\n",
    "        self.steps_beyond_done = None\n",
    "        \n",
    "        #df内の初めのレースの取り出し\n",
    "        result_com,return_money,race_data,race_data_label,race_date=self.split_race_data(self.race_ID)#いろいろ算出用にレースデータの抜き取り\n",
    "        self.state =race_data\n",
    "        \n",
    "        return np.array(self.state)\n",
    "    \n",
    "    def random_action_func(self):#ランダムな行動を生成するための関数\n",
    "        random_action=np.random.rand(28)#サイズ28のランダムな行動を生成する\n",
    "        return random_action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-spectacular",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q関数の定義\n",
    "## 入力:学習データそのまま\n",
    "## 出力:1～29(29は購買しない)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "explicit-century",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class QFunction(chainer.Chain):#chainer.Chain:link Lやfunction Fをまとめて管理するものらしい，親クラスとして提供されているためニューラルネットを定義する際はこれを継承させるらしい．\n",
    "\n",
    "    def __init__(self, obs_size, n_actions, n_hidden_channels=100):\n",
    "        super().__init__()\n",
    "        #n_actions:行動の種類数\n",
    "        #obs_size :入力データの次元数\n",
    "        #l1,l2等々は層を表してる，l2が出力層\n",
    "        with self.init_scope():\n",
    "            self.l0 = L.Linear(obs_size, n_hidden_channels)#Lはchainer.linksです（インポート時にas　L　でインポートしてる）\n",
    "            self.l1 = L.Linear(n_hidden_channels, n_hidden_channels)#Lはchainer.linksです（インポート時にas　L　でインポートしてる）\n",
    "            self.l2 = L.Linear(n_hidden_channels, n_actions)#Lはchainer.linksです（インポート時にas　L　でインポートしてる）\n",
    "\n",
    "    def __call__(self, x, test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (ndarray or chainer.Variable): An observation\n",
    "            test (bool): a flag indicating whether it is in test mode\n",
    "            [翻訳]\n",
    "            x（ndarrayまたはchainer.Variable）：観測値\n",
    "            test（bool）：テストモードかどうかを示すフラグ\n",
    "        \"\"\"\n",
    "        h = F.tanh(self.l0(x))#F は　chainer.functions\n",
    "        h = F.tanh(self.l1(h))#F は　chainer.functions\n",
    "        return chainerrl.action_value.DiscreteActionValue(self.l2(h))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-timing",
   "metadata": {},
   "source": [
    "# 試しに動かしてみる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-given",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### envのテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "funny-austin",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs [4 46.0 0.45 ... 0 0 0]\n",
      "r -8.0\n",
      "done False\n",
      "info {'total_gain': 0, 'total_income': -8.0, 'total_get': 0.0, 'total_use': 8}\n"
     ]
    }
   ],
   "source": [
    "place_name='asiya'\n",
    "cash=100000#所持金\n",
    "\n",
    "result_filepath=\"../boatracer_BOT_making/bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "sample_race_df=pd.read_csv(result_filepath)\n",
    "sample_race_df=sample_race_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "sample_race_df.head()\n",
    "sample_race_df=data_making_mo_bo(sample_race_df)#前処理\n",
    "\n",
    "asiya_env =BoatraceEnv(sample_race_df,cash)#環境の作成（クラス）\n",
    "obs = asiya_env.reset()\n",
    "\n",
    "test_action=[0,1,1,1,1,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0]#たくさん買ってるけどあたってない\n",
    "#test_action=[0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]#一点買いであたった\n",
    "#test_action=[1,2,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]#あたってる\n",
    "obs, r, done, info = asiya_env.step(test_action)\n",
    "print('obs',obs)\n",
    "print('r',r)\n",
    "print('done',done)\n",
    "print('info',info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-duplicate",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "color-clause",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "place_name='asiya'\n",
    "#cash=100000#所持金\n",
    "cash=100#所持金\n",
    "\n",
    "result_filepath=\"../boatracer_BOT_making/bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "sample_race_df=pd.read_csv(result_filepath)\n",
    "sample_race_df=sample_race_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "sample_race_df.head()\n",
    "\n",
    "asiya_env =BoatraceEnv(sample_race_df,cash)#環境の作成（クラス）\n",
    "\n",
    "#Q関数の設定\n",
    "obs_size = asiya_env.obs_size\n",
    "n_actions = asiya_env.n_action\n",
    "q_func = QFunction(obs_size, n_actions)\n",
    "#q_func.to_gpu(0) ## GPUを使いたい人はこのコメントを外す\n",
    "\n",
    "#最適化手法とパラメータ設定\n",
    "optimizer = chainer.optimizers.Adam(eps=1e-2)\n",
    "optimizer.setup(q_func) #設計したq関数の最適化にAdamを使う\n",
    "gamma = 0.80#報酬の割引率.過去の結果をどのくらい重要視するか\n",
    "explorer = chainerrl.explorers.ConstantEpsilonGreedy(#次の戦略を考えるときの方法\n",
    "    epsilon=0.3, random_action_func=asiya_env.random_action_func)\n",
    "replay_buffer = chainerrl.replay_buffer.ReplayBuffer(capacity = 10**6)#Replayを実行するかどうか\n",
    "phi = lambda x:x.astype(np.float32, copy=False)##型の変換(chainerはfloat32型。float64は駄目)\n",
    "\n",
    "agent = chainerrl.agents.DoubleDQN(\n",
    "    q_func, optimizer, replay_buffer, gamma, explorer,\n",
    "    replay_start_size=500, update_interval=1,\n",
    "    target_update_interval=100, phi=phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "drawn-system",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blessed-microwave",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 46.0 0.45 ... 0 0 0]\n",
      "1236\n"
     ]
    }
   ],
   "source": [
    "print(obs)\n",
    "print(len(obs))#入力データ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-excitement",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "false-insert",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-455c592bc20f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_episode_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact_and_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masiya_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mR\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-ef77cf07efc7>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m#それに応じて購買行動を行う(1～28で購買を行う)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m#インデックス番号＋１が購買を行う番号と対応している（はず）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mtotal_use\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#使った金額の算出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;31m#total_use=sum(action)*self.bet_coefficient#使った金額の算出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int32' object is not iterable"
     ]
    }
   ],
   "source": [
    "import time\n",
    "n_episodes = 200\n",
    "max_episode_len = 200\n",
    "start = time.time()\n",
    "for i in range(1, n_episodes + 1):\n",
    "    v = asiya_env.reset()\n",
    "    reward = 0\n",
    "    done = False\n",
    "    R = 0  # return (sum of rewards)\n",
    "    t = 0  # time step\n",
    "    while not done and t < max_episode_len:\n",
    "        action = agent.act_and_train(obs, reward)\n",
    "        obs, reward, done, _ = asiya_env.step(action)\n",
    "        R += reward\n",
    "        t += 1\n",
    "    if i % 10 == 0:\n",
    "        print('episode:', i,\n",
    "              'R:', R,\n",
    "              'statistics:', agent.get_statistics())\n",
    "    agent.stop_episode_and_train(obs, reward, done)\n",
    "print('Finished, elapsed time : {}'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "novel-daily",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "coastal-airline",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3959, 3793, 4196, 3326, 4583, 4037, 4, 1, 35.0, 0.541, 0.14, 2,\n",
       "       1, 40.0, 0.287, 0.19, 2, 1, 30.0, 0.327, 0.19, 3, 1, 45.0, 0.421,\n",
       "       0.16, 2, 1, 23.0, 0.252, 0.18, 3, 1, 34.0, 0.396, 0.19, 3.0, 43.0,\n",
       "       33.0, 40.0, 56.0, 67.0, 59.0, 45.0, 60.0, 42.0, 29.0, 47.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-greene",
   "metadata": {},
   "source": [
    "# 会場ごと，comごとにターゲットを指定して，comごとの最適な買い方を学習する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "romantic-costa",
   "metadata": {
    "code_folding": [
     144
    ]
   },
   "outputs": [],
   "source": [
    "class BoatraceComEnv:#comごとに一つの環境を設定する\n",
    "#class BoatraceEnv(必要であればここに購買金額の係数等を書いてあげる):\n",
    "    def split_race_data(self,race_ID):#レースのID(インデックス)を渡して，レースの情報を学習時などに使いやすい形に切り分けるメソッド\n",
    "        race_row=self.trans_race_df.iloc[race_ID]#対象のレースを切り抜き(series型)\n",
    "        result_com=race_row['result_com']\n",
    "        return_money=race_row['money']\n",
    "        racer_ID=race_row['money']\n",
    "        race_date=race_row['date']\n",
    "        race_data=race_row.drop(['date',\"result_com\",\"money\"]).values\n",
    "        race_data_label=race_row.drop(['date',\"result_com\",\"money\"]).index\n",
    "                                \n",
    "        #race_data:選手情報やボート・モータ番号などの予測用データが入った配列\n",
    "        #race_data_label:予測用データの役割を示す配列(pandasの列名（カラム）がこれに該当する)\n",
    "        return result_com,return_money,race_data,race_data_label,race_date\n",
    "    \n",
    "    def trans_target_result_com_df(self):#target_comに応じてresult_comを1,0にラベル変換（df用(全レース)）\n",
    "        transd_race_df=self.race_df.copy()\n",
    "        transd_race_df.loc[transd_race_df['result_com'] != self.target_com, 'result_com'] = 0#target_comと同じでないものは0とする\n",
    "        transd_race_df.loc[transd_race_df['result_com'] == self.target_com, 'result_com'] = 1#target_comと同じものは１とする\n",
    "        \n",
    "        return transd_race_df\n",
    "    \n",
    "    def trans_target_result_com_row(self,race_row):#target_comに応じてresult_comを1,0にラベル変換（行（レース単位）用）多分そんなに使わない，使うとしたら外部で使う\n",
    "        if race_row['result_com']==self.target_com:\n",
    "            race_row['result_com']=1\n",
    "        else:\n",
    "            race_row['result_com']=0\n",
    "        return trans_race_row\n",
    "    \n",
    "    def __init__(self,target_com,race_df,cash,bet_coefficient=10000,end_th_cash_magni=0.5):#メンバ等の定義\n",
    "        self.target_com=target_com#ゲームの対象とするcom\n",
    "        self.st_cash = cash#初めに持っている所持金\n",
    "        self.cash = cash#所持金（初めは上のものと同じ値が入るが，こちらの変数はゲームが進んでいくと更新されていく）\n",
    "        self.end_th_cash = cash*end_th_cash_magni#所持金がいくらを下回ったらゲームオーバーか決めるための閾値金額(end_th_cashで何パーセントを下回ったらアウトかを指定)\n",
    "        self.bet_coefficient = bet_coefficient#購買時を想定して定数倍する係数\n",
    "        self.random_state = 7#何かと生成をするときに使うためのシード値\n",
    "        self.race_ID=0#どこのレースを抜き出すかどうかの番号付け(インデックス参照で抜き出す)\n",
    "        self.total_gain = None#現時点と開始時を比較した時の利益率(reset()で要リセット)\n",
    "        self.total_use = 0#現時点までの総使用金額(reset()で要リセット)\n",
    "        self.total_get = 0#現時点までの総獲得金額(reset()で要リセット)\n",
    "        self.num_hit = 0#現時点までの総的中回数(reset()で要リセット)\n",
    "        self.num_pass = 0#現時点までの購買を行わなかった数(reset()で要リセット)\n",
    "        self.num_bet = 0#現時点までの購買行動を行った数(reset()で要リセット)\n",
    "        self.total_reward=0#報酬の合計（報酬設計の参考にする）(reset()で要リセット)\n",
    "        self.state = None#1レースあたりのデータ格納用のメンバ\n",
    "        self.steps_beyond_done = None\n",
    "        \n",
    "        #ラベル（result_com）をtarget_comをもとに変換する\n",
    "        self.race_df=race_df\n",
    "        trans_race_df=self.trans_target_result_com_df()\n",
    "        self.trans_race_df=trans_race_df#全部のレース情報のまとめdfを格納\n",
    "        \n",
    "        #Q関数定義時関連の処理\n",
    "        self.n_action=11#行動の種類(買うべき指数的な感じ（単純に倍率とするか，指数とするかは決めていない）０は購買しない，それ以降は購買で数値が上がっていくほど多くの購買を行う)\n",
    "        sample_df=self.trans_race_df\n",
    "        sample_df=sample_df.drop(['date',\"result_com\",\"money\"],axis=1)\n",
    "        self.obs_size=len(sample_df.columns)#予測に使う情報の次元数\n",
    "\n",
    "#     def seed(self, seed=None):\n",
    "#         self.np_random, seed = seeding.np_random(seed)\n",
    "#         return [seed]\n",
    "\n",
    "\n",
    "    def step(self, action):#ステップ（ゲームの報酬計算と次の環境の取得）\n",
    "        race_ID=self.race_ID\n",
    "        result_com,return_money,race_data,race_data_label,race_date=self.split_race_data(self.race_ID)#いろいろ算出用にレースデータの抜き取り\n",
    "        return_money_magni=return_money/100#配当金を倍率に変換\n",
    "        #state = self.state\n",
    "        #当たったかどうかの判別と，リターンの算出\n",
    "        #race_use=0\n",
    "        race_get=0\n",
    "        race_use=action\n",
    "        #race_use+=action*self.bet_coefficient\n",
    "        if (action!=0):\n",
    "            self.num_bet=self.num_bet+1\n",
    "            if result_com==1:#購買行動を行っていたかつ，的中した         \n",
    "                race_get=action*return_money_magni#return_money_magni:配当の倍率(magnification)\n",
    "                self.num_hit=self.num_hit+1\n",
    "                #race_get=self.bet_coefficient*action*return_money_magni#実際の購買額版，return_money_magni:配当の倍率(magnification)\n",
    "        elif(action==0):#購買を行わなかった（レースを見逃した）\n",
    "            self.num_pass =self.num_pass+1 \n",
    "        else:\n",
    "            print('error_unexpected_join_else::この警告の表示は想定されてません')\n",
    "        \n",
    "        #収支計算()\n",
    "        #race_gain=(race_get/race_use)#廃止，これだと０除算になる可能性が高い\n",
    "        race_gain=race_get-race_use#割合でなく，実際の金額で計算．（まあ本番も利益額大きい方がうれしいし？？？）\n",
    "        self.total_use+=race_use\n",
    "        self.total_get+=race_get\n",
    "        if (self.total_get!=0) and (self.total_get!=0):\n",
    "            self.total_gain=((self.total_get/self.total_use)*100)-100#利益率を計算(減ってるとマイナスになる)\n",
    "        else:\n",
    "            self.total_gain=0\n",
    "        before_cash=self.cash#購買行動を行う前の所持金を取っておく\n",
    "        self.cash=self.cash-race_use#使用金額を引く\n",
    "        self.cash=self.cash+race_get#配当金を足す\n",
    "        #diff_cash=self.cash-before_cash#購買を行う前と後の金額を比較(減ってるとマイナスになる)\n",
    "        #出現したが，見逃したことへの罰則を与える（全く買わない事が最適解と認識するのをさける）\n",
    "        if (result_com==1) and (action==0):\n",
    "            diff_cash=(self.cash-before_cash)*1.1#購買を行う前と後の金額を比較,また，出現しているのにも関わらず見逃したので罰則を与える(減ってるとマイナスになる)\n",
    "        else:\n",
    "            diff_cash=self.cash-before_cash#購買を行う前と後の金額を比較(減ってるとマイナスになる)\n",
    "        \n",
    "        #報酬の決定\n",
    "        reward=diff_cash#前のレースと比べてお金が増えたか減ったかをそのまま報酬とする\n",
    "        if reward<-100:\n",
    "            print('--------------------------------------------------------------------\\n')\n",
    "            print('=======================diff_cash:{}======================='.format(diff_cash))\n",
    "            print('=======================cash:{}======================='.format(self.cash))\n",
    "            print('=======================before_cash:{}======================='.format(before_cash))\n",
    "            print('=======================race_use:{}======================='.format(race_use))\n",
    "            print('=======================race_get:{}======================='.format(race_get))\n",
    "            print('=======================action:{}======================='.format(action))\n",
    "            print('--------------------------------------------------------------------\\n')\n",
    "#         if (diff_cash==0)and(result_com==1):\n",
    "#             reward=-15#出現しているが，見逃したものには罰則を与える\n",
    "        self.total_reward=self.total_reward+reward\n",
    "        #各種フラグの付与（ゲームが続くか続かないか）\n",
    "        if self.cash<self.end_th_cash:#所持金が指定金額以上に減ったらゲームオーバー\n",
    "            done=True\n",
    "        else:\n",
    "            done=False\n",
    "            \n",
    "        #次の観測（次のレース）の取り出し\n",
    "        self.race_ID=self.race_ID+1#次の状態を抜き出すためにIDに1を足す\n",
    "        if self.race_ID>(len(self.race_df)-1):#次の状態(レース)がなくなったら終了\n",
    "            done=True\n",
    "            self.state=None\n",
    "            reward=None\n",
    "        else:\n",
    "            result_com_next,return_money_next,race_data_next,race_data_label_next,race_date_next=self.split_race_data(self.race_ID)\n",
    "            \n",
    "        #行動分析用の追加評価値\n",
    "        #total_gain=(self.cash/self.st_cash)*100#現時点での利益率\n",
    "        total_income=self.total_get-self.total_use#獲得とそうでないものの差から，今までの利益額を算出\n",
    "        try:\n",
    "            buy_hit_per=(self.num_hit/self.num_bet)*100\n",
    "        except:\n",
    "            buy_hit_per=0\n",
    "        scores_dict={\n",
    "            'total_gain':self.total_gain ,\n",
    "            'total_income':total_income ,\n",
    "            'total_get':self.total_get ,\n",
    "            'total_use':self.total_use,\n",
    "            'num_bet':self.num_bet,\n",
    "            'num_pass':self.num_pass,\n",
    "            'num_hit':self.num_hit,\n",
    "            'buy_hit_per':buy_hit_per,\n",
    "            'total_reward':self.total_reward\n",
    "        }\n",
    "        \n",
    "        return np.array(race_data_next), reward, done, scores_dict\n",
    "\n",
    "    def reset(self):#環境の初期化用メソッド\n",
    "        self.cash = self.st_cash#スタート時の所持金\n",
    "        self.race_ID=0#どこのレースを抜き出すかどうかの番号付け(インデックス参照で抜き出す)\n",
    "        self.total_gain = None#現時点と開始時を比較した時の利益率(reset()で要リセット)\n",
    "        self.total_use = 0#現時点までの総使用金額(reset()で要リセット)\n",
    "        self.total_get = 0#現時点までの総獲得金額(reset()で要リセット)\n",
    "        self.num_hit = 0#現時点までの総的中回数(reset()で要リセット)\n",
    "        self.num_pass = 0#現時点までの購買を行わなかった数(reset()で要リセット)\n",
    "        self.num_bet = 0#現時点までの購買行動を行った数(reset()で要リセット)\n",
    "        self.total_reward=0#報酬の合計（報酬設計の参考にする）\n",
    "        self.state = None#1レースあたりのデータ格納用のメンバ\n",
    "        self.steps_beyond_done = None\n",
    "        \n",
    "        #df内の初めのレースの取り出し\n",
    "        result_com,return_money,race_data,race_data_label,race_date=self.split_race_data(self.race_ID)#いろいろ算出用にレースデータの抜き取り\n",
    "        self.state =race_data\n",
    "        \n",
    "        return np.array(self.state)\n",
    "    \n",
    "    def random_action_func(self):#ランダムな行動を生成するための関数\n",
    "        random_action=np.random.randint(11)#サイズ0～10のランダムな行動を生成する\n",
    "        return random_action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-neighborhood",
   "metadata": {},
   "source": [
    "# Q関数の定義\n",
    "## 入力:学習データそのまま\n",
    "## 出力:0～11(0は購買しない)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vietnamese-service",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class QFunction(chainer.Chain):#chainer.Chain:link Lやfunction Fをまとめて管理するものらしい，親クラスとして提供されているためニューラルネットを定義する際はこれを継承させるらしい．\n",
    "\n",
    "    def __init__(self, obs_size, n_actions, n_hidden_channels=500):\n",
    "        super().__init__()\n",
    "        #n_actions:行動の種類数\n",
    "        #obs_size :入力データの次元数\n",
    "        #l1,l2等々は層を表してる，l2が出力層\n",
    "        with self.init_scope():\n",
    "            self.l0 = L.Linear(obs_size, n_hidden_channels)#Lはchainer.linksです（インポート時にas　L　でインポートしてる）\n",
    "            self.l1 = L.Linear(n_hidden_channels, n_hidden_channels)#Lはchainer.linksです（インポート時にas　L　でインポートしてる）\n",
    "            self.l2 = L.Linear(n_hidden_channels, n_actions)#Lはchainer.linksです（インポート時にas　L　でインポートしてる）\n",
    "            #self.l3 = L.Linear(n_hidden_channels, n_actions)#Lはchainer.linksです（インポート時にas　L　でインポートしてる）\n",
    "\n",
    "    def __call__(self, x, test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (ndarray or chainer.Variable): An observation\n",
    "            test (bool): a flag indicating whether it is in test mode\n",
    "            [翻訳]\n",
    "            x（ndarrayまたはchainer.Variable）：観測値\n",
    "            test（bool）：テストモードかどうかを示すフラグ\n",
    "        \"\"\"\n",
    "        h = F.tanh(self.l0(x))#F は　chainer.functions\n",
    "        h = F.tanh(self.l1(h))#F は　chainer.functions\n",
    "        #h = F.tanh(self.l2(h))#F は　chainer.functions\n",
    "        return chainerrl.action_value.DiscreteActionValue(self.l2(h))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-cemetery",
   "metadata": {},
   "source": [
    "## テスト動作\n",
    "terget_comを一つだけにして挙動だけ確認する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-prevention",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### envのテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "clear-aquarium",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_making_mo_bo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-50a50e4e845a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msample_race_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_race_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Unnamed: 0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msample_race_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0msample_race_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_making_mo_bo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_race_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#前処理\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0masiya_env\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mBoatraceComEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_com\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msample_race_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcash\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#環境の作成（クラス）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_making_mo_bo' is not defined"
     ]
    }
   ],
   "source": [
    "place_name='asiya'\n",
    "cash=100000#所持金\n",
    "target_com=6\n",
    "#target_com=1\n",
    "\n",
    "\n",
    "result_filepath=\"../boatracer_BOT_making/bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "sample_race_df=pd.read_csv(result_filepath)\n",
    "sample_race_df=sample_race_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "sample_race_df.head()\n",
    "sample_race_df=data_making_mo_bo(sample_race_df)#前処理\n",
    "\n",
    "asiya_env =BoatraceComEnv(target_com,sample_race_df,cash)#環境の作成（クラス）\n",
    "obs = asiya_env.reset()\n",
    "\n",
    "#test_action=0#買わない\n",
    "#test_action=1#一点買いであたった\n",
    "test_action=5#あたってる\n",
    "obs, r, done, info = asiya_env.step(test_action)\n",
    "print('obs',obs)\n",
    "print('r',r)\n",
    "print('done',done)\n",
    "print('info',info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-fusion",
   "metadata": {},
   "source": [
    "### 定義テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "posted-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name='asiya'\n",
    "#cash=100000#所持金\n",
    "cash=10000#所持金\n",
    "target_com=5\n",
    "#target_com=2\n",
    "\n",
    "result_filepath=\"../../boatracer_BOT_making/bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "sample_race_df=pd.read_csv(result_filepath)\n",
    "sample_race_df=sample_race_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "sample_race_df.head()\n",
    "sample_race_df=data_making(sample_race_df)#前処理\n",
    "asiya_env =BoatraceComEnv(target_com,sample_race_df,cash)#環境の作成（クラス）\n",
    "\n",
    "#Q関数の設定\n",
    "obs_size = asiya_env.obs_size\n",
    "n_actions = asiya_env.n_action\n",
    "q_func = QFunction(obs_size, n_actions)\n",
    "q_func.to_gpu(0)\n",
    "#q_func.to_gpu(0) ## GPUを使いたい人はこのコメントを外す\n",
    "\n",
    "#最適化手法とパラメータ設定\n",
    "optimizer = chainer.optimizers.Adam(eps=1e-2)\n",
    "optimizer.setup(q_func) #設計したq関数の最適化にAdamを使う\n",
    "gamma = 0.1#報酬の割引率.過去の結果をどのくらい重要視するか\n",
    "#gamma = 0.06#報酬の割引率.過去の結果をどのくらい重要視するか\n",
    "explorer = chainerrl.explorers.ConstantEpsilonGreedy(#次の戦略を考えるときの方法\n",
    "    epsilon=0.5, random_action_func=asiya_env.random_action_func)\n",
    "replay_buffer = chainerrl.replay_buffer.ReplayBuffer(capacity = 10**6)#Replayを実行するかどうか\n",
    "phi = lambda x:x.astype(np.float32, copy=False)##型の変換(chainerはfloat32型。float64は駄目)\n",
    "\n",
    "agent = chainerrl.agents.DoubleDQN(\n",
    "    q_func, optimizer, replay_buffer, gamma, explorer,\n",
    "    replay_start_size=500, update_interval=1,\n",
    "    target_update_interval=100, phi=phi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-attention",
   "metadata": {},
   "source": [
    "### 学習テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-oracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10 R: -5003.999999999992 statistics: [('average_q', 0.0005852863086378564), ('average_loss', 1.4070702273115743), ('n_updates', 72148)]\n",
      "episode: 20 R: -5004.5999999999985 statistics: [('average_q', 0.0013269864994887312), ('average_loss', 1.7186335542091578), ('n_updates', 144856)]\n",
      "episode: 30 R: -5000.699999999998 statistics: [('average_q', 0.0067061372345844535), ('average_loss', 2.0481115257846865), ('n_updates', 213513)]\n",
      "episode: 40 R: -5002.100000000003 statistics: [('average_q', 0.002309068195762103), ('average_loss', 1.943627838346584), ('n_updates', 286548)]\n",
      "episode: 50 R: -5002.000000000006 statistics: [('average_q', 0.0008806809435824818), ('average_loss', 1.93505040880944), ('n_updates', 357060)]\n",
      "episode: 60 R: -5005.299999999991 statistics: [('average_q', 0.0020448677886511953), ('average_loss', 1.8720667060978189), ('n_updates', 428806)]\n",
      "episode: 70 R: -4747.000000000004 statistics: [('average_q', 0.003951417615749525), ('average_loss', 1.7350540681554283), ('n_updates', 504159)]\n",
      "episode: 80 R: -5001.700000000006 statistics: [('average_q', 0.005362390352856714), ('average_loss', 1.9905066325827312), ('n_updates', 569786)]\n",
      "episode: 90 R: -4935.500000000003 statistics: [('average_q', 0.0014281427162549383), ('average_loss', 1.6687099932252674), ('n_updates', 648103)]\n",
      "episode: 100 R: -3815.399999999998 statistics: [('average_q', 0.002115432318685789), ('average_loss', 2.2405712509716387), ('n_updates', 723144)]\n",
      "episode: 110 R: -3317.800000000003 statistics: [('average_q', 0.0013213998577934155), ('average_loss', 1.9246550471859698), ('n_updates', 795614)]\n",
      "episode: 120 R: -2640.2000000000016 statistics: [('average_q', 0.0013550167847009877), ('average_loss', 1.505270388674786), ('n_updates', 869726)]\n",
      "episode: 130 R: -5002.500000000006 statistics: [('average_q', 0.0034831833550570783), ('average_loss', 2.3396359723300426), ('n_updates', 940920)]\n",
      "episode: 140 R: -5004.9 statistics: [('average_q', 0.011935997903923686), ('average_loss', 1.7017958202591712), ('n_updates', 1014980)]\n",
      "episode: 150 R: -5002.499999999995 statistics: [('average_q', 0.010806924649014803), ('average_loss', 1.6553351066165205), ('n_updates', 1089112)]\n",
      "episode: 160 R: -3807.499999999992 statistics: [('average_q', 0.003229789554311747), ('average_loss', 1.719056734415964), ('n_updates', 1167710)]\n",
      "episode: 170 R: -4137.400000000005 statistics: [('average_q', 0.0066691262902808714), ('average_loss', 1.845327902477236), ('n_updates', 1244141)]\n",
      "episode: 180 R: -4228.300000000001 statistics: [('average_q', 0.007381752902747842), ('average_loss', 2.200375498544511), ('n_updates', 1318157)]\n",
      "episode: 190 R: -5000.300000000001 statistics: [('average_q', 0.027133452617378893), ('average_loss', 2.0897512691216797), ('n_updates', 1389479)]\n",
      "episode: 200 R: -5001.300000000006 statistics: [('average_q', 0.01887981850419344), ('average_loss', 1.747337648119943), ('n_updates', 1465992)]\n",
      "episode: 210 R: -5008.200000000004 statistics: [('average_q', 0.04442872923661949), ('average_loss', 1.6025032156111152), ('n_updates', 1542280)]\n",
      "episode: 220 R: -5004.399999999999 statistics: [('average_q', 0.06793995394127744), ('average_loss', 1.9746139099302662), ('n_updates', 1611745)]\n",
      "episode: 230 R: -5002.999999999999 statistics: [('average_q', 0.08750268442235382), ('average_loss', 2.203996317672787), ('n_updates', 1688150)]\n",
      "episode: 240 R: -3849.7000000000035 statistics: [('average_q', 0.018975244809387986), ('average_loss', 1.7135268127767993), ('n_updates', 1759945)]\n",
      "episode: 250 R: -5003.399999999995 statistics: [('average_q', 0.024866552886159382), ('average_loss', 1.8056660551627455), ('n_updates', 1838512)]\n",
      "episode: 260 R: -3310.7000000000016 statistics: [('average_q', 0.028674383720393957), ('average_loss', 1.7049604689318971), ('n_updates', 1915818)]\n",
      "episode: 270 R: -2776.5000000000036 statistics: [('average_q', 0.048009516375689315), ('average_loss', 1.8321980657713661), ('n_updates', 1990890)]\n",
      "episode: 280 R: -3678.7000000000044 statistics: [('average_q', 0.03250231987332264), ('average_loss', 2.144398689794139), ('n_updates', 2067165)]\n",
      "episode: 290 R: -3412.5999999999976 statistics: [('average_q', 0.028678549728653222), ('average_loss', 2.031375740883605), ('n_updates', 2143618)]\n",
      "episode: 300 R: -4326.599999999999 statistics: [('average_q', 0.036952702747634), ('average_loss', 1.6562894680216644), ('n_updates', 2219742)]\n",
      "episode: 310 R: -5003.9 statistics: [('average_q', 0.06327121818928241), ('average_loss', 2.2926457530669313), ('n_updates', 2298746)]\n",
      "episode: 320 R: -3487.0000000000073 statistics: [('average_q', 0.039692396595762), ('average_loss', 2.194334231983305), ('n_updates', 2374016)]\n",
      "episode: 330 R: -2485.7000000000016 statistics: [('average_q', 0.03776257779071063), ('average_loss', 2.1561857741867336), ('n_updates', 2450195)]\n",
      "episode: 340 R: -5006.999999999999 statistics: [('average_q', 0.051344322294898104), ('average_loss', 2.028814507746296), ('n_updates', 2528481)]\n",
      "episode: 350 R: -3536.70000000001 statistics: [('average_q', 0.04908900990975037), ('average_loss', 2.1293304041200316), ('n_updates', 2608083)]\n",
      "episode: 360 R: -2013.800000000001 statistics: [('average_q', 0.06242254225205387), ('average_loss', 1.7503694441725757), ('n_updates', 2683316)]\n",
      "episode: 370 R: -2986.099999999996 statistics: [('average_q', 0.07506195720650975), ('average_loss', 1.853704945935769), ('n_updates', 2760773)]\n",
      "episode: 380 R: -2277.799999999994 statistics: [('average_q', 0.06744430524125494), ('average_loss', 2.2425706427913266), ('n_updates', 2835938)]\n",
      "episode: 390 R: -4710.9 statistics: [('average_q', 0.06290176484212995), ('average_loss', 1.696061467641681), ('n_updates', 2913697)]\n",
      "episode: 400 R: -3909.4000000000033 statistics: [('average_q', 0.07786483912278948), ('average_loss', 1.8944299442158348), ('n_updates', 2991343)]\n",
      "episode: 410 R: -3990.5000000000036 statistics: [('average_q', 0.08099427545645346), ('average_loss', 1.7130818812532425), ('n_updates', 3069569)]\n",
      "episode: 420 R: -5002.5 statistics: [('average_q', 0.179133997467245), ('average_loss', 1.6275331118333236), ('n_updates', 3148255)]\n",
      "episode: 430 R: -5001.200000000002 statistics: [('average_q', 0.21173356031360738), ('average_loss', 2.0558125183201947), ('n_updates', 3222580)]\n",
      "episode: 440 R: -1840.2000000000025 statistics: [('average_q', 0.08054201314967797), ('average_loss', 1.6700326583607208), ('n_updates', 3299742)]\n",
      "episode: 450 R: -5000.400000000007 statistics: [('average_q', 0.16727244622987106), ('average_loss', 1.7308552174336962), ('n_updates', 3374620)]\n",
      "episode: 460 R: -3757.0999999999967 statistics: [('average_q', 0.0782300241052875), ('average_loss', 1.565208484333168), ('n_updates', 3451707)]\n",
      "episode: 470 R: -3499.099999999995 statistics: [('average_q', 0.07065033415985017), ('average_loss', 1.6613277273082163), ('n_updates', 3523330)]\n",
      "episode: 480 R: -5000.499999999996 statistics: [('average_q', 0.19164901259558448), ('average_loss', 1.8746767742832182), ('n_updates', 3598811)]\n",
      "episode: 490 R: -3934.0 statistics: [('average_q', 0.07097950342476987), ('average_loss', 1.8542273831801543), ('n_updates', 3677371)]\n",
      "episode: 500 R: -3553.700000000007 statistics: [('average_q', 0.07107874809228111), ('average_loss', 1.6545284285198314), ('n_updates', 3754947)]\n",
      "episode: 510 R: -3357.4000000000024 statistics: [('average_q', 0.07220087203330985), ('average_loss', 2.0460293616029057), ('n_updates', 3832810)]\n",
      "episode: 520 R: -2549.0 statistics: [('average_q', 0.08124399135289763), ('average_loss', 1.6963997884289745), ('n_updates', 3912810)]\n",
      "episode: 530 R: -4245.7000000000035 statistics: [('average_q', 0.08196571688492393), ('average_loss', 1.5178029792137477), ('n_updates', 3988823)]\n",
      "episode: 540 R: -5002.100000000005 statistics: [('average_q', 0.25868028912331664), ('average_loss', 2.2207291871109667), ('n_updates', 4066455)]\n",
      "episode: 550 R: -2683.0 statistics: [('average_q', 0.07296573248003094), ('average_loss', 1.7936146698206354), ('n_updates', 4142216)]\n",
      "episode: 560 R: -5001.700000000001 statistics: [('average_q', 0.08695896720366866), ('average_loss', 1.800742298602204), ('n_updates', 4219459)]\n",
      "episode: 570 R: -3404.5999999999995 statistics: [('average_q', 0.08205017509496249), ('average_loss', 1.8613682358282297), ('n_updates', 4296404)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 580 R: -5009.599999999997 statistics: [('average_q', 0.09522904338069028), ('average_loss', 1.9042474213775546), ('n_updates', 4376034)]\n",
      "episode: 590 R: -3495.899999999994 statistics: [('average_q', 0.08217727181181383), ('average_loss', 1.9040138579531454), ('n_updates', 4452936)]\n",
      "episode: 600 R: -1485.5000000000073 statistics: [('average_q', 0.07199110578688231), ('average_loss', 1.8383700291462386), ('n_updates', 4530007)]\n",
      "episode: 610 R: -3519.4000000000005 statistics: [('average_q', 0.05677675637556914), ('average_loss', 1.894208615975405), ('n_updates', 4605339)]\n",
      "episode: 620 R: -174.60000000000036 statistics: [('average_q', 0.05461443876844856), ('average_loss', 1.6280649823306326), ('n_updates', 4680244)]\n",
      "episode: 630 R: -1117.8999999999996 statistics: [('average_q', 0.0556764885575185), ('average_loss', 1.8942559566610075), ('n_updates', 4756801)]\n",
      "episode: 640 R: -3404.4999999999955 statistics: [('average_q', 0.05475048647510598), ('average_loss', 1.9348341031764977), ('n_updates', 4834536)]\n",
      "episode: 650 R: -3803.899999999996 statistics: [('average_q', 0.0554669938659971), ('average_loss', 1.8715509493070377), ('n_updates', 4910378)]\n",
      "episode: 660 R: -5000.899999999999 statistics: [('average_q', 0.1445919045904616), ('average_loss', 2.1295020367092414), ('n_updates', 4987866)]\n",
      "episode: 670 R: -4540.599999999992 statistics: [('average_q', 0.05451378156920955), ('average_loss', 1.6375598438181886), ('n_updates', 5064958)]\n",
      "episode: 680 R: -3034.0000000000073 statistics: [('average_q', 0.05585119645387243), ('average_loss', 2.0313627881267764), ('n_updates', 5144170)]\n",
      "episode: 690 R: -3433.0999999999976 statistics: [('average_q', 0.055342620311376094), ('average_loss', 2.206377989221142), ('n_updates', 5219253)]\n",
      "episode: 700 R: -3353.200000000007 statistics: [('average_q', 0.05543221372219334), ('average_loss', 1.5782779778929206), ('n_updates', 5295851)]\n",
      "episode: 710 R: -3746.000000000008 statistics: [('average_q', 0.056437756913326656), ('average_loss', 1.6092151855644683), ('n_updates', 5370630)]\n",
      "episode: 720 R: -3727.800000000003 statistics: [('average_q', 0.05557719876573199), ('average_loss', 2.2661359388605726), ('n_updates', 5443439)]\n",
      "episode: 730 R: -5005.100000000002 statistics: [('average_q', 0.13432709472472684), ('average_loss', 1.7170295711133317), ('n_updates', 5520874)]\n",
      "episode: 740 R: -5004.199999999999 statistics: [('average_q', 0.1417632438879406), ('average_loss', 2.0436884513117577), ('n_updates', 5597628)]\n",
      "episode: 750 R: -2776.699999999998 statistics: [('average_q', 0.05672400613456711), ('average_loss', 1.9448757742238902), ('n_updates', 5675769)]\n",
      "episode: 760 R: -4076.400000000004 statistics: [('average_q', 0.054468062517777686), ('average_loss', 2.115757604357772), ('n_updates', 5753211)]\n",
      "episode: 770 R: -2704.099999999994 statistics: [('average_q', 0.05570193234384879), ('average_loss', 1.8946985717264482), ('n_updates', 5828401)]\n",
      "episode: 780 R: -3235.900000000006 statistics: [('average_q', 0.05546014758604919), ('average_loss', 1.8297743021846193), ('n_updates', 5905078)]\n",
      "episode: 790 R: -3011.4000000000024 statistics: [('average_q', 0.05557987579467514), ('average_loss', 2.2744483013699455), ('n_updates', 5983428)]\n",
      "episode: 800 R: -2267.999999999998 statistics: [('average_q', 0.055987434922387114), ('average_loss', 2.0581902522685236), ('n_updates', 6060002)]\n",
      "episode: 810 R: -3684.2000000000044 statistics: [('average_q', 0.05514921028591459), ('average_loss', 2.5348215918223693), ('n_updates', 6137346)]\n",
      "episode: 820 R: -3918.899999999998 statistics: [('average_q', 0.05667859871501335), ('average_loss', 2.0694676768763145), ('n_updates', 6214831)]\n",
      "episode: 830 R: -5004.999999999997 statistics: [('average_q', 0.1510686374914279), ('average_loss', 1.6816390299746655), ('n_updates', 6289646)]\n",
      "episode: 840 R: -3227.999999999998 statistics: [('average_q', 0.05599172939160599), ('average_loss', 2.3007101307377784), ('n_updates', 6366871)]\n",
      "episode: 850 R: -2520.5999999999985 statistics: [('average_q', 0.05565744188274147), ('average_loss', 2.0818120406459046), ('n_updates', 6441919)]\n",
      "episode: 860 R: -3842.8999999999987 statistics: [('average_q', 0.05520379396994098), ('average_loss', 1.8246653638796608), ('n_updates', 6519932)]\n",
      "episode: 870 R: -5002.499999999999 statistics: [('average_q', 0.14612919186151396), ('average_loss', 2.261035623345154), ('n_updates', 6594420)]\n",
      "episode: 880 R: -2976.2999999999965 statistics: [('average_q', 0.05724713370568644), ('average_loss', 2.274612335908168), ('n_updates', 6669935)]\n",
      "episode: 890 R: -4942.800000000001 statistics: [('average_q', 0.05779729812274818), ('average_loss', 1.9937941129522783), ('n_updates', 6749935)]\n",
      "episode: 900 R: -4203.499999999999 statistics: [('average_q', 0.0561560774362158), ('average_loss', 2.0112397724981297), ('n_updates', 6828092)]\n",
      "episode: 910 R: -4311.299999999999 statistics: [('average_q', 0.05552372783891334), ('average_loss', 1.660525572268762), ('n_updates', 6900937)]\n",
      "episode: 920 R: -3869.000000000002 statistics: [('average_q', 0.05613057741321442), ('average_loss', 1.5944270190985201), ('n_updates', 6978014)]\n",
      "episode: 930 R: -5001.400000000002 statistics: [('average_q', 0.14789459909445124), ('average_loss', 1.9516117360359413), ('n_updates', 7054529)]\n",
      "episode: 940 R: -4953.199999999999 statistics: [('average_q', 0.05662596249248153), ('average_loss', 1.6688192717867731), ('n_updates', 7133447)]\n",
      "episode: 950 R: -3553.800000000004 statistics: [('average_q', 0.057559196453510826), ('average_loss', 1.8401697668068957), ('n_updates', 7210204)]\n",
      "episode: 960 R: -5006.199999999997 statistics: [('average_q', 0.15075146292138797), ('average_loss', 1.8300187248607407), ('n_updates', 7284718)]\n",
      "episode: 970 R: -4208.7 statistics: [('average_q', 0.05758469538440922), ('average_loss', 1.6622902902029075), ('n_updates', 7363906)]\n",
      "episode: 980 R: -5002.400000000001 statistics: [('average_q', 0.07559397885789086), ('average_loss', 1.7955123750483757), ('n_updates', 7440038)]\n",
      "episode: 990 R: -1832.699999999999 statistics: [('average_q', 0.0562133322804317), ('average_loss', 2.0771417062194972), ('n_updates', 7514850)]\n",
      "episode: 1000 R: -4753.499999999997 statistics: [('average_q', 0.05675238180610142), ('average_loss', 1.9280276480621048), ('n_updates', 7590705)]\n",
      "episode: 1010 R: -4046.2999999999975 statistics: [('average_q', 0.05722905125166136), ('average_loss', 2.3106993121172392), ('n_updates', 7668041)]\n",
      "episode: 1020 R: -2087.0999999999985 statistics: [('average_q', 0.057432550179381245), ('average_loss', 2.104494410763268), ('n_updates', 7744559)]\n",
      "episode: 1030 R: -1329.9000000000015 statistics: [('average_q', 0.058336962503465054), ('average_loss', 1.866472731137747), ('n_updates', 7823501)]\n",
      "episode: 1040 R: -4774.1 statistics: [('average_q', 0.056749191370594886), ('average_loss', 1.6329096462834), ('n_updates', 7893678)]\n",
      "episode: 1050 R: -1993.599999999993 statistics: [('average_q', 0.05715738825223056), ('average_loss', 2.1258017786159207), ('n_updates', 7969621)]\n",
      "episode: 1060 R: -2524.199999999999 statistics: [('average_q', 0.057497606623168385), ('average_loss', 2.1008840436917753), ('n_updates', 8044392)]\n",
      "episode: 1070 R: -3859.800000000002 statistics: [('average_q', 0.05712119343399933), ('average_loss', 2.1711459234304016), ('n_updates', 8120711)]\n",
      "episode: 1080 R: -2915.7999999999956 statistics: [('average_q', 0.05771354890125315), ('average_loss', 1.9706295481786007), ('n_updates', 8198061)]\n",
      "episode: 1090 R: -5004.700000000002 statistics: [('average_q', 0.1525425072425744), ('average_loss', 1.884812096960861), ('n_updates', 8275851)]\n",
      "episode: 1100 R: -1916.599999999995 statistics: [('average_q', 0.05752653184418537), ('average_loss', 1.6566624863167638), ('n_updates', 8355786)]\n",
      "episode: 1110 R: -4644.799999999999 statistics: [('average_q', 0.05816558180662482), ('average_loss', 1.5287248029681415), ('n_updates', 8435786)]\n",
      "episode: 1120 R: -4832.899999999998 statistics: [('average_q', 0.059358590069269135), ('average_loss', 1.7044352513211414), ('n_updates', 8513415)]\n",
      "episode: 1130 R: -4428.699999999999 statistics: [('average_q', 0.05760859204578529), ('average_loss', 1.7211348621659215), ('n_updates', 8587139)]\n",
      "episode: 1140 R: -5003.300000000006 statistics: [('average_q', 0.07558904482016347), ('average_loss', 2.060544337390096), ('n_updates', 8664620)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1150 R: -5008.600000000004 statistics: [('average_q', 0.10090452842538794), ('average_loss', 1.6127052338660377), ('n_updates', 8740829)]\n",
      "episode: 1160 R: -4908.300000000005 statistics: [('average_q', 0.05686271206945644), ('average_loss', 1.76675056521241), ('n_updates', 8819823)]\n",
      "episode: 1170 R: -4086.899999999995 statistics: [('average_q', 0.0567724151796725), ('average_loss', 1.6716472706742507), ('n_updates', 8896046)]\n",
      "episode: 1180 R: -5002.299999999997 statistics: [('average_q', 0.15945502745696002), ('average_loss', 1.5463390700789101), ('n_updates', 8970021)]\n",
      "episode: 1190 R: -3063.599999999994 statistics: [('average_q', 0.058390850396029675), ('average_loss', 1.4350856588568133), ('n_updates', 9047898)]\n",
      "episode: 1200 R: -3987.600000000004 statistics: [('average_q', 0.06975289431493459), ('average_loss', 2.027429964737844), ('n_updates', 9124258)]\n",
      "episode: 1210 R: -4298.699999999998 statistics: [('average_q', 0.058533590091270175), ('average_loss', 1.8484192537193014), ('n_updates', 9200193)]\n",
      "episode: 1220 R: -4693.999999999999 statistics: [('average_q', 0.057895904435109266), ('average_loss', 1.4841790660275114), ('n_updates', 9278109)]\n",
      "episode: 1230 R: -3812.300000000004 statistics: [('average_q', 0.05852493337475546), ('average_loss', 2.0330151440067765), ('n_updates', 9356664)]\n",
      "episode: 1240 R: -5006.100000000006 statistics: [('average_q', 0.1290956016065677), ('average_loss', 1.7056075330892644), ('n_updates', 9435855)]\n",
      "episode: 1250 R: -4290.199999999996 statistics: [('average_q', 0.0578425486603405), ('average_loss', 2.1720439456138148), ('n_updates', 9514854)]\n",
      "episode: 1260 R: -3052.600000000002 statistics: [('average_q', 0.05863590129295556), ('average_loss', 1.449065631078087), ('n_updates', 9592896)]\n",
      "episode: 1270 R: -4162.899999999997 statistics: [('average_q', 0.058317536730266746), ('average_loss', 2.0093605396563596), ('n_updates', 9669354)]\n",
      "episode: 1280 R: -5000.399999999995 statistics: [('average_q', 0.07779359304998099), ('average_loss', 2.043404829870037), ('n_updates', 9745384)]\n",
      "episode: 1290 R: -4615.0 statistics: [('average_q', 0.06065413976641228), ('average_loss', 1.8655658981820353), ('n_updates', 9823944)]\n",
      "episode: 1300 R: -3246.700000000009 statistics: [('average_q', 0.05877484301490458), ('average_loss', 1.6714809521097602), ('n_updates', 9901546)]\n",
      "episode: 1310 R: -4627.899999999995 statistics: [('average_q', 0.06017642304278113), ('average_loss', 1.601073634494449), ('n_updates', 9979074)]\n",
      "episode: 1320 R: -1245.6999999999935 statistics: [('average_q', 0.0600349630095615), ('average_loss', 2.2229675421248443), ('n_updates', 10059074)]\n",
      "episode: 1330 R: -3638.7 statistics: [('average_q', 0.060168517577247844), ('average_loss', 2.3909582511454883), ('n_updates', 10139039)]\n",
      "episode: 1340 R: -3384.100000000005 statistics: [('average_q', 0.06049801781043662), ('average_loss', 1.9790156280666933), ('n_updates', 10214823)]\n",
      "episode: 1350 R: -5006.400000000003 statistics: [('average_q', 0.14440544694266705), ('average_loss', 1.7584403392504), ('n_updates', 10292178)]\n",
      "episode: 1360 R: -4679.6 statistics: [('average_q', 0.06118552577362047), ('average_loss', 1.9310338297958756), ('n_updates', 10366371)]\n",
      "episode: 1370 R: -5000.700000000001 statistics: [('average_q', 0.1463914617230219), ('average_loss', 2.0552177035029424), ('n_updates', 10445470)]\n",
      "episode: 1380 R: -3288.399999999995 statistics: [('average_q', 0.08233137383887626), ('average_loss', 1.6367696659930289), ('n_updates', 10523707)]\n",
      "episode: 1390 R: -5000.800000000002 statistics: [('average_q', 0.10142452175731326), ('average_loss', 1.7027093117652659), ('n_updates', 10600395)]\n",
      "episode: 1400 R: -5005.900000000001 statistics: [('average_q', 0.18347932843120282), ('average_loss', 1.9424148286356684), ('n_updates', 10675279)]\n",
      "episode: 1410 R: -4623.099999999997 statistics: [('average_q', 0.13208179343359866), ('average_loss', 1.8406922257076528), ('n_updates', 10753454)]\n",
      "episode: 1420 R: -5000.300000000007 statistics: [('average_q', 0.07749486919564284), ('average_loss', 2.0792111908110567), ('n_updates', 10833002)]\n",
      "episode: 1430 R: -5000.700000000002 statistics: [('average_q', 0.2381649855156139), ('average_loss', 2.2099252790571415), ('n_updates', 10909579)]\n",
      "episode: 1440 R: -1444.7999999999993 statistics: [('average_q', 0.14216777784029022), ('average_loss', 1.7760492738429532), ('n_updates', 10987555)]\n",
      "episode: 1450 R: -1408.7000000000007 statistics: [('average_q', 0.14857505973153912), ('average_loss', 2.080921529609261), ('n_updates', 11063010)]\n",
      "episode: 1460 R: -1598.5000000000055 statistics: [('average_q', 0.11413595407992798), ('average_loss', 2.1083011082152208), ('n_updates', 11141303)]\n",
      "episode: 1470 R: -5002.200000000002 statistics: [('average_q', 0.17172798236418493), ('average_loss', 1.7636112948750957), ('n_updates', 11219177)]\n",
      "episode: 1480 R: -3796.2999999999965 statistics: [('average_q', 0.10171186148553144), ('average_loss', 1.705090969779396), ('n_updates', 11296437)]\n",
      "episode: 1490 R: -2238.500000000002 statistics: [('average_q', 0.10309111335831977), ('average_loss', 1.6057532366874634), ('n_updates', 11376437)]\n",
      "episode: 1500 R: -3101.9000000000115 statistics: [('average_q', 0.1144360744513307), ('average_loss', 2.0254012937770454), ('n_updates', 11456265)]\n",
      "episode: 1510 R: -2545.2 statistics: [('average_q', 0.09823772916852704), ('average_loss', 2.1028449816312653), ('n_updates', 11531897)]\n",
      "episode: 1520 R: -4398.600000000003 statistics: [('average_q', 0.09811628029175264), ('average_loss', 1.8999757031969207), ('n_updates', 11610291)]\n",
      "episode: 1530 R: -4525.0 statistics: [('average_q', 0.10596145179534691), ('average_loss', 1.6982308753542295), ('n_updates', 11690291)]\n",
      "episode: 1540 R: 231.79999999999745 statistics: [('average_q', 0.11364135368860874), ('average_loss', 2.038965195723765), ('n_updates', 11766752)]\n",
      "episode: 1550 R: -3030.7000000000035 statistics: [('average_q', 0.08608659327010831), ('average_loss', 1.914355439694251), ('n_updates', 11844579)]\n",
      "episode: 1560 R: -3397.1999999999953 statistics: [('average_q', 0.09967384451115958), ('average_loss', 1.4126295755006548), ('n_updates', 11921640)]\n",
      "episode: 1570 R: -5001.500000000004 statistics: [('average_q', 0.17808197162799128), ('average_loss', 1.5878025802891977), ('n_updates', 11997224)]\n",
      "episode: 1580 R: -3559.6000000000004 statistics: [('average_q', 0.09767811078883086), ('average_loss', 1.812725235234033), ('n_updates', 12077224)]\n",
      "episode: 1590 R: -3214.999999999992 statistics: [('average_q', 0.11504462948633085), ('average_loss', 2.130500766188468), ('n_updates', 12153704)]\n",
      "episode: 1600 R: -2854.5000000000045 statistics: [('average_q', 0.10711738033514782), ('average_loss', 1.7138385897380337), ('n_updates', 12229053)]\n",
      "episode: 1610 R: -1758.0000000000036 statistics: [('average_q', 0.12535320296117838), ('average_loss', 2.050608345868441), ('n_updates', 12307618)]\n",
      "episode: 1620 R: -3454.6000000000013 statistics: [('average_q', 0.09891793775797518), ('average_loss', 1.5306866031378126), ('n_updates', 12386171)]\n",
      "episode: 1630 R: -2064.6999999999953 statistics: [('average_q', 0.16906271603166617), ('average_loss', 1.6237921398054311), ('n_updates', 12460490)]\n",
      "episode: 1640 R: -5008.900000000006 statistics: [('average_q', 0.2052933002828162), ('average_loss', 1.775559046917745), ('n_updates', 12538165)]\n",
      "episode: 1650 R: -2663.6000000000013 statistics: [('average_q', 0.18459790658374287), ('average_loss', 2.2728615136433064), ('n_updates', 12614567)]\n",
      "episode: 1660 R: -3322.0000000000064 statistics: [('average_q', 0.17400111901654972), ('average_loss', 1.5340086356274427), ('n_updates', 12694567)]\n",
      "episode: 1670 R: -5007.699999999998 statistics: [('average_q', 0.15654878584054477), ('average_loss', 1.879428272388139), ('n_updates', 12769409)]\n",
      "episode: 1680 R: -3383.499999999998 statistics: [('average_q', 0.18466633298787183), ('average_loss', 1.5353706723784784), ('n_updates', 12847089)]\n",
      "episode: 1690 R: -4171.299999999997 statistics: [('average_q', 0.17371085825873822), ('average_loss', 1.7123746756502085), ('n_updates', 12923820)]\n",
      "episode: 1700 R: -3086.300000000001 statistics: [('average_q', 0.17008598865286134), ('average_loss', 1.7688928477790296), ('n_updates', 12998803)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1710 R: -3204.3000000000075 statistics: [('average_q', 0.1870322961673089), ('average_loss', 1.7989809277041429), ('n_updates', 13072676)]\n",
      "episode: 1720 R: -4051.000000000002 statistics: [('average_q', 0.08167256665374094), ('average_loss', 1.6140260663372554), ('n_updates', 13150569)]\n",
      "episode: 1730 R: -5003.800000000003 statistics: [('average_q', 0.27348477471386323), ('average_loss', 1.7799114179614335), ('n_updates', 13225156)]\n",
      "episode: 1740 R: -3644.3000000000084 statistics: [('average_q', 0.18200194327077898), ('average_loss', 1.405647009423366), ('n_updates', 13303642)]\n",
      "episode: 1750 R: -3977.2000000000035 statistics: [('average_q', 0.1927964714156563), ('average_loss', 2.026486471984026), ('n_updates', 13382090)]\n",
      "episode: 1760 R: -2138.299999999992 statistics: [('average_q', 0.21047810967986555), ('average_loss', 2.236837494831333), ('n_updates', 13460864)]\n",
      "episode: 1770 R: -5002.299999999993 statistics: [('average_q', 0.15114810057320513), ('average_loss', 1.5727020450194826), ('n_updates', 13540271)]\n",
      "episode: 1780 R: -2281.2000000000016 statistics: [('average_q', 0.20039927750730055), ('average_loss', 1.7061308164056697), ('n_updates', 13618794)]\n",
      "episode: 1790 R: -5006.900000000001 statistics: [('average_q', 0.17131915300571798), ('average_loss', 2.396693663255624), ('n_updates', 13694016)]\n",
      "episode: 1800 R: -4316.4999999999945 statistics: [('average_q', 0.21126885069191068), ('average_loss', 1.853685876238551), ('n_updates', 13772429)]\n",
      "episode: 1810 R: -5000.4000000000015 statistics: [('average_q', 0.2535965285258219), ('average_loss', 2.0775747445146067), ('n_updates', 13848978)]\n",
      "episode: 1820 R: -3540.699999999999 statistics: [('average_q', 0.22926881471028138), ('average_loss', 1.875699843166153), ('n_updates', 13928839)]\n",
      "episode: 1830 R: -3000.7000000000035 statistics: [('average_q', 0.248209485236398), ('average_loss', 1.2837543014692934), ('n_updates', 14008839)]\n",
      "episode: 1840 R: -3657.2000000000007 statistics: [('average_q', 0.27719274150676876), ('average_loss', 2.218682967357805), ('n_updates', 14088468)]\n",
      "episode: 1850 R: -5005.100000000007 statistics: [('average_q', 0.16778371587850022), ('average_loss', 1.865692040974383), ('n_updates', 14167862)]\n",
      "episode: 1860 R: -2334.000000000001 statistics: [('average_q', 0.26938333812389015), ('average_loss', 2.1573049475622037), ('n_updates', 14246750)]\n",
      "episode: 1870 R: -2120.2000000000035 statistics: [('average_q', 0.28156545807971733), ('average_loss', 1.7562671482355172), ('n_updates', 14325636)]\n",
      "episode: 1880 R: -247.8000000000011 statistics: [('average_q', 0.27887619043663386), ('average_loss', 1.6942600975242692), ('n_updates', 14404554)]\n",
      "episode: 1890 R: -5008.300000000001 statistics: [('average_q', 0.28079384762609155), ('average_loss', 1.4714201761100305), ('n_updates', 14478937)]\n",
      "episode: 1900 R: -3898.3999999999987 statistics: [('average_q', 0.27001171872576873), ('average_loss', 1.8807958781773748), ('n_updates', 14558384)]\n",
      "episode: 1910 R: -4745.4999999999945 statistics: [('average_q', 0.27782883094820415), ('average_loss', 2.0394354490213313), ('n_updates', 14635591)]\n",
      "episode: 1920 R: -2951.5999999999995 statistics: [('average_q', 0.2797623447878111), ('average_loss', 2.1208194762597037), ('n_updates', 14713561)]\n",
      "episode: 1930 R: -4130.800000000005 statistics: [('average_q', 0.2776692762128937), ('average_loss', 1.7193393335060836), ('n_updates', 14792259)]\n",
      "episode: 1940 R: -4647.799999999997 statistics: [('average_q', 0.27901095953955796), ('average_loss', 2.0208445370103836), ('n_updates', 14868865)]\n",
      "episode: 1950 R: -2157.600000000002 statistics: [('average_q', 0.27889266336604784), ('average_loss', 1.7468197439349105), ('n_updates', 14946161)]\n",
      "episode: 1960 R: -1686.5 statistics: [('average_q', 0.2799281418020349), ('average_loss', 1.4172923907717874), ('n_updates', 15025221)]\n",
      "episode: 1970 R: -3547.200000000008 statistics: [('average_q', 0.2771846623395308), ('average_loss', 1.7814961273213865), ('n_updates', 15104571)]\n",
      "episode: 1980 R: -3066.8 statistics: [('average_q', 0.2784210971026768), ('average_loss', 1.8988446493608115), ('n_updates', 15179476)]\n",
      "episode: 1990 R: -2878.8999999999996 statistics: [('average_q', 0.27831133230907296), ('average_loss', 1.8730692956465063), ('n_updates', 15258065)]\n",
      "episode: 2000 R: -3371.900000000004 statistics: [('average_q', 0.2792340452287934), ('average_loss', 2.2665880049501426), ('n_updates', 15338065)]\n",
      "episode: 2010 R: -3735.999999999998 statistics: [('average_q', 0.27846154342290125), ('average_loss', 1.6672384207052333), ('n_updates', 15417227)]\n",
      "episode: 2020 R: -2372.899999999998 statistics: [('average_q', 0.27804856870130895), ('average_loss', 1.6873799048390337), ('n_updates', 15495383)]\n",
      "episode: 2030 R: -4289.200000000001 statistics: [('average_q', 0.2781595866860456), ('average_loss', 1.7637585395323567), ('n_updates', 15575383)]\n",
      "episode: 2040 R: -3624.499999999992 statistics: [('average_q', 0.1642904693732328), ('average_loss', 1.4861176313437836), ('n_updates', 15653497)]\n",
      "episode: 2050 R: -5001.599999999991 statistics: [('average_q', 0.24044016450728573), ('average_loss', 1.835508927026411), ('n_updates', 15732134)]\n",
      "episode: 2060 R: -4309.200000000004 statistics: [('average_q', 0.2789215342443007), ('average_loss', 1.8782737558494724), ('n_updates', 15811292)]\n",
      "episode: 2070 R: -3351.4000000000024 statistics: [('average_q', 0.28205330189018607), ('average_loss', 2.225825554707946), ('n_updates', 15891212)]\n",
      "episode: 2080 R: -2038.7999999999956 statistics: [('average_q', 0.2788293839715185), ('average_loss', 1.7864628528663606), ('n_updates', 15970412)]\n",
      "episode: 2090 R: -2617.3999999999987 statistics: [('average_q', 0.27982772821093704), ('average_loss', 1.8636735002794802), ('n_updates', 16048628)]\n",
      "episode: 2100 R: -2705.7999999999975 statistics: [('average_q', 0.2833198309375963), ('average_loss', 1.6063567811189052), ('n_updates', 16128458)]\n",
      "episode: 2110 R: -2240.300000000001 statistics: [('average_q', 0.2805018116294276), ('average_loss', 2.0900539774192053), ('n_updates', 16205765)]\n",
      "episode: 2120 R: -3512.1999999999907 statistics: [('average_q', 0.28343758678334274), ('average_loss', 1.7096627504298112), ('n_updates', 16282069)]\n",
      "episode: 2130 R: -3806.199999999998 statistics: [('average_q', 0.28006400538207404), ('average_loss', 2.0013755158296003), ('n_updates', 16359555)]\n",
      "episode: 2140 R: -4119.199999999995 statistics: [('average_q', 0.2807974622237798), ('average_loss', 1.7187074390097916), ('n_updates', 16438939)]\n",
      "episode: 2150 R: -3436.399999999995 statistics: [('average_q', 0.2809340856334664), ('average_loss', 2.0849021384501096), ('n_updates', 16516341)]\n",
      "episode: 2160 R: -1918.3999999999924 statistics: [('average_q', 0.2823676700844325), ('average_loss', 2.1893721543878666), ('n_updates', 16591282)]\n",
      "episode: 2170 R: -2950.299999999991 statistics: [('average_q', 0.259242244809454), ('average_loss', 1.724250106542199), ('n_updates', 16668010)]\n",
      "episode: 2180 R: -2679.499999999998 statistics: [('average_q', 0.25355908284044815), ('average_loss', 2.1814017900632567), ('n_updates', 16746292)]\n",
      "episode: 2190 R: -3353.4000000000005 statistics: [('average_q', 0.2560326185623876), ('average_loss', 2.243603562189684), ('n_updates', 16824656)]\n",
      "episode: 2200 R: -2416.700000000007 statistics: [('average_q', 0.25173102759016946), ('average_loss', 1.921046470722144), ('n_updates', 16898967)]\n",
      "episode: 2210 R: -3674.500000000001 statistics: [('average_q', 0.25305784119840297), ('average_loss', 1.9995438676103845), ('n_updates', 16978967)]\n",
      "episode: 2220 R: -3898.1999999999935 statistics: [('average_q', 0.25307054086514824), ('average_loss', 1.8048700454896935), ('n_updates', 17056768)]\n",
      "episode: 2230 R: -5001.300000000002 statistics: [('average_q', 0.18406580705739514), ('average_loss', 1.5133955653570688), ('n_updates', 17133303)]\n",
      "episode: 2240 R: -3427.7999999999956 statistics: [('average_q', 0.25078432793148464), ('average_loss', 1.5012132386686534), ('n_updates', 17212133)]\n",
      "episode: 2250 R: -2783.2999999999993 statistics: [('average_q', 0.2527197814051963), ('average_loss', 2.121444985568045), ('n_updates', 17287768)]\n",
      "episode: 2260 R: -4819.199999999999 statistics: [('average_q', 0.25116645201161775), ('average_loss', 1.7509324739930563), ('n_updates', 17367364)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2270 R: -3058.300000000002 statistics: [('average_q', 0.25275809035879737), ('average_loss', 1.708102195612327), ('n_updates', 17445570)]\n",
      "episode: 2280 R: -4321.599999999999 statistics: [('average_q', 0.28993506748436504), ('average_loss', 1.820430404504569), ('n_updates', 17522903)]\n",
      "episode: 2290 R: -1579.7000000000062 statistics: [('average_q', 0.18404891810862786), ('average_loss', 1.8007840053514803), ('n_updates', 17600870)]\n",
      "episode: 2300 R: -3164.600000000003 statistics: [('average_q', 0.2819261121823776), ('average_loss', 1.6328200022233825), ('n_updates', 17679683)]\n",
      "episode: 2310 R: -5000.400000000004 statistics: [('average_q', 0.34539565687745416), ('average_loss', 2.196683722442548), ('n_updates', 17754238)]\n",
      "episode: 2320 R: -4739.499999999994 statistics: [('average_q', 0.2908124835785965), ('average_loss', 2.1020624620392394), ('n_updates', 17834035)]\n",
      "episode: 2330 R: -5004.700000000003 statistics: [('average_q', 0.27124410052133563), ('average_loss', 2.286405695124697), ('n_updates', 17909595)]\n",
      "episode: 2340 R: -2428.4999999999973 statistics: [('average_q', 0.34591326141364603), ('average_loss', 1.7204359814233199), ('n_updates', 17987357)]\n",
      "episode: 2350 R: -5004.200000000003 statistics: [('average_q', 0.16851492503261764), ('average_loss', 1.9086727348872499), ('n_updates', 18063028)]\n",
      "episode: 2360 R: -3251.499999999998 statistics: [('average_q', 0.36058272872286146), ('average_loss', 1.8410053125082977), ('n_updates', 18139448)]\n",
      "episode: 2370 R: -3497.5000000000064 statistics: [('average_q', 0.3666434275585765), ('average_loss', 1.6598460462683424), ('n_updates', 18219448)]\n",
      "episode: 2380 R: -3336.699999999996 statistics: [('average_q', 0.3388968519937234), ('average_loss', 1.3883282835511166), ('n_updates', 18298609)]\n",
      "episode: 2390 R: -3533.100000000004 statistics: [('average_q', 0.4806750456827994), ('average_loss', 1.8548423085156553), ('n_updates', 18378609)]\n",
      "episode: 2400 R: -3542.1000000000113 statistics: [('average_q', 0.35019075307672465), ('average_loss', 1.7393207645365245), ('n_updates', 18457747)]\n",
      "episode: 2410 R: -680.2000000000025 statistics: [('average_q', 0.3327322106743857), ('average_loss', 1.9772777840659628), ('n_updates', 18536680)]\n",
      "episode: 2420 R: -4455.799999999998 statistics: [('average_q', 0.35420255713067333), ('average_loss', 1.5180717345667079), ('n_updates', 18615880)]\n",
      "episode: 2430 R: -3433.499999999992 statistics: [('average_q', 0.36662944336412373), ('average_loss', 1.9673585160027112), ('n_updates', 18695716)]\n",
      "episode: 2440 R: -2520.7000000000053 statistics: [('average_q', 0.34677728290091014), ('average_loss', 2.1000414309834152), ('n_updates', 18775191)]\n",
      "episode: 2450 R: -634.0000000000018 statistics: [('average_q', 0.36529101257981306), ('average_loss', 1.62321169593955), ('n_updates', 18855191)]\n",
      "episode: 2460 R: -2477.7999999999947 statistics: [('average_q', 0.365957607936428), ('average_loss', 1.4878655704808883), ('n_updates', 18935191)]\n",
      "episode: 2470 R: -2113.699999999998 statistics: [('average_q', 0.3642373634936224), ('average_loss', 1.5236086607256136), ('n_updates', 19015191)]\n",
      "episode: 2480 R: -3772.9000000000033 statistics: [('average_q', 0.36678502516134337), ('average_loss', 2.152919641294036), ('n_updates', 19095191)]\n",
      "episode: 2490 R: -3003.7000000000053 statistics: [('average_q', 0.364448874324093), ('average_loss', 2.030929573868433), ('n_updates', 19175191)]\n",
      "episode: 2500 R: -3737.100000000003 statistics: [('average_q', 0.36320709175046445), ('average_loss', 2.4365039135729956), ('n_updates', 19255191)]\n",
      "episode: 2510 R: -2248.1999999999935 statistics: [('average_q', 0.3633913059029483), ('average_loss', 1.7038486304868248), ('n_updates', 19331658)]\n",
      "episode: 2520 R: -2013.7000000000062 statistics: [('average_q', 0.35543278600957223), ('average_loss', 1.9016393776003808), ('n_updates', 19410818)]\n",
      "episode: 2530 R: -1112.900000000005 statistics: [('average_q', 0.3715127097000532), ('average_loss', 2.1860151415416644), ('n_updates', 19489200)]\n",
      "episode: 2540 R: -524.7999999999993 statistics: [('average_q', 0.3560424290077753), ('average_loss', 1.9193216739322958), ('n_updates', 19568981)]\n",
      "episode: 2550 R: -2492.5000000000036 statistics: [('average_q', 0.36346069213293947), ('average_loss', 1.7344931998600852), ('n_updates', 19647363)]\n",
      "episode: 2560 R: -2074.3999999999924 statistics: [('average_q', 0.36345547299591957), ('average_loss', 2.0003932642193587), ('n_updates', 19727363)]\n",
      "episode: 2570 R: -4369.099999999999 statistics: [('average_q', 0.3616663698912157), ('average_loss', 1.8263224751033176), ('n_updates', 19802433)]\n",
      "episode: 2580 R: -3524.0 statistics: [('average_q', 0.36531841197525444), ('average_loss', 2.0300040964230077), ('n_updates', 19882433)]\n",
      "episode: 2590 R: -2166.200000000007 statistics: [('average_q', 0.365268564874978), ('average_loss', 1.8833673628855783), ('n_updates', 19960342)]\n",
      "episode: 2600 R: -3807.9000000000024 statistics: [('average_q', 0.3601538658094006), ('average_loss', 1.8939049484053498), ('n_updates', 20040342)]\n",
      "episode: 2610 R: -1549.7999999999938 statistics: [('average_q', 0.36310869532141543), ('average_loss', 1.9272184080756236), ('n_updates', 20119500)]\n",
      "episode: 2620 R: -3864.5 statistics: [('average_q', 0.36159612192197793), ('average_loss', 1.880793162472001), ('n_updates', 20197300)]\n",
      "episode: 2630 R: -3345.0000000000027 statistics: [('average_q', 0.3456835602382687), ('average_loss', 1.6952887723318746), ('n_updates', 20276696)]\n",
      "episode: 2640 R: -3694.6000000000013 statistics: [('average_q', 0.36128168692977786), ('average_loss', 1.8189391039776666), ('n_updates', 20355158)]\n",
      "episode: 2650 R: -1266.100000000004 statistics: [('average_q', 0.36388373654686834), ('average_loss', 2.0100858894036233), ('n_updates', 20429937)]\n",
      "episode: 2660 R: -1707.7000000000007 statistics: [('average_q', 0.3629626082156466), ('average_loss', 1.687855940741686), ('n_updates', 20508981)]\n",
      "episode: 2670 R: -622.0000000000036 statistics: [('average_q', 0.36438596059144385), ('average_loss', 1.8047606078597778), ('n_updates', 20587839)]\n",
      "episode: 2680 R: -2864.300000000001 statistics: [('average_q', 0.3625781104788342), ('average_loss', 1.3742146132586197), ('n_updates', 20665105)]\n",
      "episode: 2690 R: -2134.5000000000073 statistics: [('average_q', 0.37202442625686544), ('average_loss', 1.8087357354510942), ('n_updates', 20742756)]\n",
      "episode: 2700 R: -1587.600000000004 statistics: [('average_q', 0.36131355205571003), ('average_loss', 1.5054202894746644), ('n_updates', 20821746)]\n",
      "episode: 2710 R: -2250.5999999999976 statistics: [('average_q', 0.36113280432735434), ('average_loss', 2.2650961017886218), ('n_updates', 20899603)]\n",
      "episode: 2720 R: -5000.099999999999 statistics: [('average_q', 0.22992425751231826), ('average_loss', 1.8427027262985758), ('n_updates', 20976650)]\n",
      "episode: 2730 R: -4829.300000000001 statistics: [('average_q', 0.3632570729870208), ('average_loss', 1.7700762947339215), ('n_updates', 21053938)]\n",
      "episode: 2740 R: -2767.799999999994 statistics: [('average_q', 0.3629552801997225), ('average_loss', 1.7777452273974927), ('n_updates', 21132164)]\n",
      "episode: 2750 R: -3553.0999999999967 statistics: [('average_q', 0.37200811693064284), ('average_loss', 2.224834450726803), ('n_updates', 21212164)]\n",
      "episode: 2760 R: -3754.2000000000007 statistics: [('average_q', 0.36277196897555053), ('average_loss', 1.7530928285813117), ('n_updates', 21289667)]\n",
      "episode: 2770 R: -4138.300000000004 statistics: [('average_q', 0.36449267826582615), ('average_loss', 1.713365047125151), ('n_updates', 21369667)]\n",
      "episode: 2780 R: -1563.9999999999964 statistics: [('average_q', 0.3633317466554051), ('average_loss', 1.828790402160752), ('n_updates', 21447299)]\n",
      "episode: 2790 R: -3401.799999999991 statistics: [('average_q', 0.41793114962228667), ('average_loss', 1.5776492188445463), ('n_updates', 21527299)]\n",
      "episode: 2800 R: -2540.300000000001 statistics: [('average_q', 0.4028639750145052), ('average_loss', 1.6748352666799236), ('n_updates', 21603919)]\n",
      "episode: 2810 R: -4244.2000000000035 statistics: [('average_q', 0.37627762147774063), ('average_loss', 1.4119062430890417), ('n_updates', 21682326)]\n",
      "episode: 2820 R: -3812.5999999999995 statistics: [('average_q', 0.37278486314939807), ('average_loss', 1.7665367003523451), ('n_updates', 21759455)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2830 R: -5003.499999999996 statistics: [('average_q', 0.4377434557813546), ('average_loss', 1.8414089485575384), ('n_updates', 21838802)]\n",
      "episode: 2840 R: -5004.400000000002 statistics: [('average_q', 0.20793987896393792), ('average_loss', 1.7940234285218115), ('n_updates', 21916943)]\n",
      "episode: 2850 R: -1265.4999999999927 statistics: [('average_q', 0.4282170438041705), ('average_loss', 2.07128506307136), ('n_updates', 21996100)]\n",
      "episode: 2860 R: -2802.199999999997 statistics: [('average_q', 0.33653795681102044), ('average_loss', 1.9492868131148404), ('n_updates', 22073686)]\n",
      "episode: 2870 R: -3793.4000000000024 statistics: [('average_q', 0.16164283444078972), ('average_loss', 1.7816829611657274), ('n_updates', 22152701)]\n",
      "episode: 2880 R: -2831.800000000002 statistics: [('average_q', 0.4343550035404836), ('average_loss', 2.1965077011496716), ('n_updates', 22229743)]\n",
      "episode: 2890 R: -3874.399999999997 statistics: [('average_q', 0.3397034568597332), ('average_loss', 1.6844707361690727), ('n_updates', 22305722)]\n",
      "episode: 2900 R: -2541.1000000000104 statistics: [('average_q', 0.3264496733442355), ('average_loss', 2.0440876862476745), ('n_updates', 22385722)]\n",
      "episode: 2910 R: -4286.899999999999 statistics: [('average_q', 0.3167069752312386), ('average_loss', 1.6805577053446838), ('n_updates', 22461678)]\n",
      "episode: 2920 R: -5001.299999999998 statistics: [('average_q', 0.19108220328238534), ('average_loss', 2.0956027035091123), ('n_updates', 22538498)]\n",
      "episode: 2930 R: -1610.6000000000004 statistics: [('average_q', 0.3211897361994947), ('average_loss', 1.8176696353345032), ('n_updates', 22616656)]\n",
      "episode: 2940 R: -2970.899999999998 statistics: [('average_q', 0.3564133515367238), ('average_loss', 1.3679953939831435), ('n_updates', 22695679)]\n",
      "episode: 2950 R: -2634.199999999998 statistics: [('average_q', 0.3640028560219728), ('average_loss', 1.8523382478469488), ('n_updates', 22772533)]\n",
      "episode: 2960 R: -2327.900000000005 statistics: [('average_q', 0.3609666837082856), ('average_loss', 1.8206275263574874), ('n_updates', 22849870)]\n",
      "episode: 2970 R: -4327.0 statistics: [('average_q', 0.3609959769796162), ('average_loss', 1.815176680017731), ('n_updates', 22928608)]\n",
      "episode: 2980 R: -1285.8999999999996 statistics: [('average_q', 0.362400778641518), ('average_loss', 1.796943352295438), ('n_updates', 23006898)]\n",
      "episode: 2990 R: -2049.2999999999947 statistics: [('average_q', 0.3684540832428556), ('average_loss', 1.7539740494746332), ('n_updates', 23084513)]\n",
      "episode: 3000 R: -5004.7 statistics: [('average_q', 0.42405589059038823), ('average_loss', 1.6499090152705964), ('n_updates', 23159391)]\n",
      "episode: 3010 R: -3533.899999999997 statistics: [('average_q', 0.34664628052170976), ('average_loss', 1.9908548894814682), ('n_updates', 23239391)]\n",
      "episode: 3020 R: -1654.2999999999938 statistics: [('average_q', 0.35378034881559933), ('average_loss', 1.9505849065427687), ('n_updates', 23319297)]\n",
      "episode: 3030 R: -2474.7000000000016 statistics: [('average_q', 0.3635603339918375), ('average_loss', 1.6881883026543811), ('n_updates', 23398036)]\n",
      "episode: 3040 R: -4224.699999999999 statistics: [('average_q', 0.36137701011786433), ('average_loss', 1.5051294552408683), ('n_updates', 23475624)]\n",
      "episode: 3050 R: -1331.699999999999 statistics: [('average_q', 0.3192084566579351), ('average_loss', 1.879941921838237), ('n_updates', 23553147)]\n",
      "episode: 3060 R: -5004.700000000002 statistics: [('average_q', 0.20928514345844917), ('average_loss', 1.9480308459486382), ('n_updates', 23628428)]\n",
      "episode: 3070 R: -2815.3999999999996 statistics: [('average_q', 0.3576072134216534), ('average_loss', 1.768085509732164), ('n_updates', 23706286)]\n",
      "episode: 3080 R: -1555.699999999997 statistics: [('average_q', 0.36474837476082056), ('average_loss', 1.824331303361587), ('n_updates', 23786286)]\n",
      "episode: 3090 R: -3871.500000000008 statistics: [('average_q', 0.36592112667494564), ('average_loss', 2.0833790016727916), ('n_updates', 23860431)]\n",
      "episode: 3100 R: 288.70000000000255 statistics: [('average_q', 0.36937678136793745), ('average_loss', 1.7910450832340317), ('n_updates', 23938690)]\n",
      "episode: 3110 R: -4782.300000000001 statistics: [('average_q', 0.360344500146896), ('average_loss', 1.8020505510539757), ('n_updates', 24018690)]\n",
      "episode: 3120 R: -3881.1000000000085 statistics: [('average_q', 0.34537962333936495), ('average_loss', 1.668630795182497), ('n_updates', 24093266)]\n",
      "episode: 3130 R: -1479.6000000000058 statistics: [('average_q', 0.3622422292809661), ('average_loss', 1.6723465516622233), ('n_updates', 24172792)]\n",
      "episode: 3140 R: -3944.1999999999925 statistics: [('average_q', 0.36401213951343653), ('average_loss', 1.760060135511813), ('n_updates', 24252792)]\n",
      "episode: 3150 R: -1193.400000000007 statistics: [('average_q', 0.3527154024022788), ('average_loss', 2.3030315544862585), ('n_updates', 24327898)]\n",
      "episode: 3160 R: -4173.599999999995 statistics: [('average_q', 0.36398976093218316), ('average_loss', 1.7637941004632418), ('n_updates', 24406576)]\n",
      "episode: 3170 R: -3834.0000000000055 statistics: [('average_q', 0.3536219164726251), ('average_loss', 1.7597686374626427), ('n_updates', 24484660)]\n",
      "episode: 3180 R: -2609.199999999996 statistics: [('average_q', 0.3645695544493177), ('average_loss', 1.5892732090340496), ('n_updates', 24564660)]\n",
      "episode: 3190 R: -3836.8999999999996 statistics: [('average_q', 0.36491227294539785), ('average_loss', 1.9044838408896576), ('n_updates', 24644660)]\n",
      "episode: 3200 R: -4076.7000000000025 statistics: [('average_q', 0.36473220588468247), ('average_loss', 1.7959173507318238), ('n_updates', 24724660)]\n",
      "episode: 3210 R: -2445.2000000000135 statistics: [('average_q', 0.3627926838509987), ('average_loss', 2.060806621771195), ('n_updates', 24804660)]\n",
      "episode: 3220 R: -1253.1000000000095 statistics: [('average_q', 0.3839904956117065), ('average_loss', 1.6450833998102836), ('n_updates', 24883542)]\n",
      "episode: 3230 R: -2579.1999999999925 statistics: [('average_q', 0.3202972089872593), ('average_loss', 2.0426834269866343), ('n_updates', 24959913)]\n",
      "episode: 3240 R: -2739.1000000000067 statistics: [('average_q', 0.3529745723639604), ('average_loss', 1.7755897561828182), ('n_updates', 25039913)]\n",
      "episode: 3250 R: -2039.2000000000053 statistics: [('average_q', 0.36007887055099613), ('average_loss', 1.827742705336604), ('n_updates', 25118870)]\n",
      "episode: 3260 R: -1919.1000000000076 statistics: [('average_q', 0.36474623042912824), ('average_loss', 1.4604010394015166), ('n_updates', 25198870)]\n",
      "episode: 3270 R: -3796.0999999999985 statistics: [('average_q', 0.36365046126046974), ('average_loss', 1.7532505073248505), ('n_updates', 25278870)]\n",
      "episode: 3280 R: -1750.6000000000004 statistics: [('average_q', 0.35905328701766437), ('average_loss', 1.911004237196365), ('n_updates', 25356833)]\n",
      "episode: 3290 R: -3173.800000000001 statistics: [('average_q', 0.35911458348317815), ('average_loss', 1.7964497666863843), ('n_updates', 25436833)]\n",
      "episode: 3300 R: -3137.2999999999993 statistics: [('average_q', 0.3657153542610768), ('average_loss', 1.886551306390384), ('n_updates', 25516026)]\n",
      "episode: 3310 R: -2988.5999999999976 statistics: [('average_q', 0.36430698014582646), ('average_loss', 1.8946736513283686), ('n_updates', 25596026)]\n",
      "episode: 3320 R: -2666.7000000000053 statistics: [('average_q', 0.3651389984165481), ('average_loss', 1.8255165585796698), ('n_updates', 25676026)]\n",
      "episode: 3330 R: -3710.699999999996 statistics: [('average_q', 0.36733508284399347), ('average_loss', 1.977529468160907), ('n_updates', 25756026)]\n",
      "episode: 3340 R: -3901.7999999999965 statistics: [('average_q', 0.3577301967529013), ('average_loss', 1.417024648903024), ('n_updates', 25836026)]\n",
      "episode: 3350 R: -3851.399999999996 statistics: [('average_q', 0.3817437943512479), ('average_loss', 1.9622543099339427), ('n_updates', 25916026)]\n",
      "episode: 3360 R: -2788.9000000000015 statistics: [('average_q', 0.4200541254633149), ('average_loss', 1.8710812048478298), ('n_updates', 25995948)]\n",
      "episode: 3370 R: 479.9999999999982 statistics: [('average_q', 0.3706400671230259), ('average_loss', 1.7834578600225564), ('n_updates', 26075948)]\n",
      "episode: 3380 R: -3799.9000000000005 statistics: [('average_q', 0.36992450828407747), ('average_loss', 1.7981057149385438), ('n_updates', 26153218)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3390 R: -2655.9000000000005 statistics: [('average_q', 0.32511249146108806), ('average_loss', 1.6491336663712044), ('n_updates', 26230548)]\n",
      "episode: 3400 R: -3618.100000000006 statistics: [('average_q', 0.3666310448395796), ('average_loss', 1.4964748506409185), ('n_updates', 26309016)]\n",
      "episode: 3410 R: -2645.800000000004 statistics: [('average_q', 0.37075738757675797), ('average_loss', 1.9951149196817954), ('n_updates', 26389016)]\n",
      "episode: 3420 R: -2349.2000000000107 statistics: [('average_q', 0.21377983718479335), ('average_loss', 2.0645728192630415), ('n_updates', 26469016)]\n",
      "episode: 3430 R: -3070.8000000000075 statistics: [('average_q', 0.3274981374355103), ('average_loss', 1.7535422235331224), ('n_updates', 26549016)]\n",
      "episode: 3440 R: -594.9000000000087 statistics: [('average_q', 0.3273049518966247), ('average_loss', 1.669682363176944), ('n_updates', 26626542)]\n",
      "episode: 3450 R: -5001.600000000002 statistics: [('average_q', 0.3434730550703762), ('average_loss', 1.216136966129112), ('n_updates', 26705019)]\n",
      "episode: 3460 R: -670.7999999999993 statistics: [('average_q', 0.32786412252994507), ('average_loss', 2.378280570016489), ('n_updates', 26785019)]\n",
      "episode: 3470 R: -2045.9000000000033 statistics: [('average_q', 0.3270091689913855), ('average_loss', 1.75854102508154), ('n_updates', 26864018)]\n",
      "episode: 3480 R: -2511.5999999999913 statistics: [('average_q', 0.3228981334358774), ('average_loss', 1.3959863099889342), ('n_updates', 26939663)]\n",
      "episode: 3490 R: -4075.499999999999 statistics: [('average_q', 0.32863574614809204), ('average_loss', 1.634651279357038), ('n_updates', 27018697)]\n",
      "episode: 3500 R: -3513.900000000004 statistics: [('average_q', 0.3387029407922112), ('average_loss', 1.86833828255548), ('n_updates', 27098697)]\n",
      "episode: 3510 R: -4499.399999999999 statistics: [('average_q', 0.43175981643173056), ('average_loss', 1.7428175156211823), ('n_updates', 27178697)]\n",
      "episode: 3520 R: -3775.2000000000016 statistics: [('average_q', 0.34351505881587574), ('average_loss', 1.320270524516538), ('n_updates', 27258697)]\n",
      "episode: 3530 R: -4587.100000000007 statistics: [('average_q', 0.43726736815564937), ('average_loss', 1.8165182611523039), ('n_updates', 27338697)]\n",
      "episode: 3540 R: -2366.8999999999987 statistics: [('average_q', 0.34159326862430117), ('average_loss', 1.964915884859644), ('n_updates', 27418581)]\n",
      "episode: 3550 R: -2706.4000000000033 statistics: [('average_q', 0.2558424983257762), ('average_loss', 1.5749306292125256), ('n_updates', 27498581)]\n",
      "episode: 3560 R: -2841.300000000002 statistics: [('average_q', 0.33486929839173174), ('average_loss', 1.8650731985772067), ('n_updates', 27578581)]\n",
      "episode: 3570 R: -5007.8 statistics: [('average_q', 0.2648195572060059), ('average_loss', 1.9777660076241859), ('n_updates', 27656899)]\n",
      "episode: 3580 R: -4079.600000000003 statistics: [('average_q', 0.31650949218122193), ('average_loss', 1.8773615675559292), ('n_updates', 27733702)]\n",
      "episode: 3590 R: -2536.2000000000035 statistics: [('average_q', 0.32080584279850427), ('average_loss', 1.6434779366529917), ('n_updates', 27813702)]\n",
      "episode: 3600 R: -5009.500000000003 statistics: [('average_q', 0.41452507266170713), ('average_loss', 2.071033692320114), ('n_updates', 27892270)]\n",
      "episode: 3610 R: -3902.7999999999984 statistics: [('average_q', 0.33309354835729005), ('average_loss', 1.716541407555306), ('n_updates', 27970361)]\n",
      "episode: 3620 R: -4592.600000000001 statistics: [('average_q', 0.1351085325462462), ('average_loss', 1.7967259219124754), ('n_updates', 28050235)]\n",
      "episode: 3630 R: -2300.9000000000024 statistics: [('average_q', 0.34772130547710806), ('average_loss', 1.9179975984924513), ('n_updates', 28129659)]\n",
      "episode: 3640 R: -2468.8000000000047 statistics: [('average_q', 0.33818458775054655), ('average_loss', 2.338765441255455), ('n_updates', 28209659)]\n",
      "episode: 3650 R: -2915.600000000003 statistics: [('average_q', 0.3231304416991803), ('average_loss', 2.1136768208044097), ('n_updates', 28289416)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "n_episodes = 4000\n",
    "max_episode_len = 8000\n",
    "start = time.time()\n",
    "episode_step=list()\n",
    "scores_df=pd.DataFrame(columns=['total_gain','total_income','total_get','total_use','num_bet','num_pass','num_hit','buy_hit_per'])\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = asiya_env.reset()\n",
    "    reward = 0\n",
    "    done = False\n",
    "    R = 0  # return (sum of rewards)\n",
    "    t = 0  # time step\n",
    "    while not done and t < max_episode_len:\n",
    "        action = agent.act_and_train(obs, reward)\n",
    "        obs, reward, done, option = asiya_env.step(action)\n",
    "        R += reward\n",
    "        t += 1\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print('episode:', i,\n",
    "              'R:', R,\n",
    "              'statistics:', agent.get_statistics())\n",
    "    agent.stop_episode_and_train(obs, reward, done)\n",
    "    add_df = pd.DataFrame.from_dict(option, orient='index').T\n",
    "    scores_df = pd.concat([scores_df, add_df], axis=0)\n",
    "    episode_step.append(i)\n",
    "    scores_df.to_csv('csv/gamma_01_long.csv')\n",
    "    #エピソードごとの成績を作成\n",
    "scores_df['n_episode']=episode_step\n",
    "print('Finished, elapsed time : {}'.format(time.time()-start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-resource",
   "metadata": {},
   "source": [
    "### テスト　学習過程の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-equality",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def larning_plt(df,x_n,y_n):#2本軸でのグラフの描写\n",
    "    fig = plt.figure(figsize=(19,8))\n",
    "    plt.tick_params(colors='black')\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    fig.set_facecolor(color='white')\n",
    "\n",
    "    x=df[x_n].values\n",
    "    y=df[y_n].values\n",
    "\n",
    "    ax1 = fig.add_subplot()\n",
    "    #ax1.plot(x, y,label=y_n, marker=\"o\")\n",
    "    ax1.plot(x, y,label=y_n)\n",
    "    ax1.tick_params()\n",
    "    \n",
    "    h1, l1 = ax1.get_legend_handles_labels()\n",
    "    ax1.legend(h1, l1)\n",
    "\n",
    "    ax1.set_xlabel(x_n)\n",
    "    ax1.set_ylabel(y_n)\n",
    "    plt.axhline(y=0,color='red')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "for col in scores_df.columns:\n",
    "    x_n='n_episode'\n",
    "    y_n=col\n",
    "    larning_plt(scores_df,x_n,y_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "major-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_csv('csv/20220803.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-thong",
   "metadata": {},
   "source": [
    "## GPUの使用でどれくらい短縮効果があるかの確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-miracle",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GPUなし:911sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conservative-jacket",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10 R: -269454.1750000002 statistics: [('average_q', -0.08670020672760897), ('average_loss', 112.53643541119972), ('n_updates', 19500)]\n",
      "episode: 20 R: -231561.5200000003 statistics: [('average_q', -0.175727651092178), ('average_loss', 133.41969647892438), ('n_updates', 39500)]\n",
      "episode: 30 R: -254537.3250000003 statistics: [('average_q', -0.12066549715352473), ('average_loss', 135.91506888733377), ('n_updates', 59500)]\n",
      "episode: 40 R: -285264.0250000004 statistics: [('average_q', 0.025761359124444258), ('average_loss', 116.76136684894085), ('n_updates', 79500)]\n",
      "episode: 50 R: -294924.93500000035 statistics: [('average_q', 0.006402642496736394), ('average_loss', 125.70122892190575), ('n_updates', 99500)]\n",
      "Finished, elapsed time : 911.2012474536896\n"
     ]
    }
   ],
   "source": [
    "place_name='asiya'\n",
    "#cash=100000#所持金\n",
    "cash=100000#所持金\n",
    "target_com=5\n",
    "#target_com=2\n",
    "\n",
    "result_filepath=\"../boatracer_BOT_making/bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "sample_race_df=pd.read_csv(result_filepath)\n",
    "sample_race_df=sample_race_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "sample_race_df.head()\n",
    "sample_race_df=data_making(sample_race_df)#前処理\n",
    "asiya_env =BoatraceComEnv(target_com,sample_race_df,cash)#環境の作成（クラス）\n",
    "\n",
    "#Q関数の設定\n",
    "obs_size = asiya_env.obs_size\n",
    "n_actions = asiya_env.n_action\n",
    "q_func = QFunction(obs_size, n_actions)\n",
    "#q_func.to_gpu(0) ## GPUを使いたい人はこのコメントを外す\n",
    "\n",
    "#最適化手法とパラメータ設定\n",
    "optimizer = chainer.optimizers.Adam(eps=1e-2)\n",
    "optimizer.setup(q_func) #設計したq関数の最適化にAdamを使う\n",
    "gamma = 0.80#報酬の割引率.過去の結果をどのくらい重要視するか\n",
    "explorer = chainerrl.explorers.ConstantEpsilonGreedy(#次の戦略を考えるときの方法\n",
    "    epsilon=0.3, random_action_func=asiya_env.random_action_func)\n",
    "replay_buffer = chainerrl.replay_buffer.ReplayBuffer(capacity = 10**6)#Replayを実行するかどうか\n",
    "phi = lambda x:x.astype(np.float32, copy=False)##型の変換(chainerはfloat32型。float64は駄目)\n",
    "\n",
    "agent = chainerrl.agents.DoubleDQN(\n",
    "    q_func, optimizer, replay_buffer, gamma, explorer,\n",
    "    replay_start_size=500, update_interval=1,\n",
    "    target_update_interval=100, phi=phi)\n",
    "\n",
    "import time\n",
    "n_episodes = 50\n",
    "max_episode_len = 2000\n",
    "start = time.time()\n",
    "episode_step=list()\n",
    "episode_gain=list()\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = asiya_env.reset()\n",
    "    reward = 0\n",
    "    done = False\n",
    "    R = 0  # return (sum of rewards)\n",
    "    t = 0  # time step\n",
    "    while not done and t < max_episode_len:\n",
    "        action = agent.act_and_train(obs, reward)\n",
    "        obs, reward, done, option = asiya_env.step(action)\n",
    "        R += reward\n",
    "        t += 1\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print('episode:', i,\n",
    "              'R:', R,\n",
    "              'statistics:', agent.get_statistics())\n",
    "    agent.stop_episode_and_train(obs, reward, done)\n",
    "    episode_step.append(i)\n",
    "    episode_gain.append(asiya_env.total_gain)\n",
    "    #エピソードごとの成績を作成\n",
    "    \n",
    "print('Finished, elapsed time : {}'.format(time.time()-start))\n",
    "analysis_df=pd.DataFrame()\n",
    "analysis_df['ep_step']=episode_step\n",
    "analysis_df['ep_gain']=episode_gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-favorite",
   "metadata": {},
   "source": [
    "### GPUあり:665sec==早い！！,今度っからこっちでやる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "elder-invention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10 R: -224802.09500000026 statistics: [('average_q', -0.06732089490786068), ('average_loss', 120.95386273199466), ('n_updates', 19500)]\n",
      "episode: 20 R: -259868.58000000034 statistics: [('average_q', -0.23308289401661836), ('average_loss', 123.8925704501554), ('n_updates', 39500)]\n",
      "episode: 30 R: -239620.52000000014 statistics: [('average_q', -0.16733844107282406), ('average_loss', 111.26403850712934), ('n_updates', 59500)]\n",
      "episode: 40 R: -274908.9250000003 statistics: [('average_q', -0.12391317265966276), ('average_loss', 114.4313894115869), ('n_updates', 79500)]\n",
      "episode: 50 R: -225254.43500000035 statistics: [('average_q', -0.1331655710723999), ('average_loss', 124.27176601905643), ('n_updates', 99500)]\n",
      "Finished, elapsed time : 665.4870507717133\n"
     ]
    }
   ],
   "source": [
    "place_name='asiya'\n",
    "#cash=100000#所持金\n",
    "cash=100000#所持金\n",
    "target_com=5\n",
    "#target_com=2\n",
    "\n",
    "result_filepath=\"../boatracer_BOT_making/bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "sample_race_df=pd.read_csv(result_filepath)\n",
    "sample_race_df=sample_race_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "sample_race_df.head()\n",
    "sample_race_df=data_making(sample_race_df)#前処理\n",
    "asiya_env =BoatraceComEnv(target_com,sample_race_df,cash)#環境の作成（クラス）\n",
    "\n",
    "#Q関数の設定\n",
    "obs_size = asiya_env.obs_size\n",
    "n_actions = asiya_env.n_action\n",
    "q_func = QFunction(obs_size, n_actions)\n",
    "q_func.to_gpu(0)\n",
    "#q_func.to_gpu(0) ## GPUを使いたい人はこのコメントを外す\n",
    "\n",
    "#最適化手法とパラメータ設定\n",
    "optimizer = chainer.optimizers.Adam(eps=1e-2)\n",
    "optimizer.setup(q_func) #設計したq関数の最適化にAdamを使う\n",
    "gamma = 0.80#報酬の割引率.過去の結果をどのくらい重要視するか\n",
    "explorer = chainerrl.explorers.ConstantEpsilonGreedy(#次の戦略を考えるときの方法\n",
    "    epsilon=0.3, random_action_func=asiya_env.random_action_func)\n",
    "replay_buffer = chainerrl.replay_buffer.ReplayBuffer(capacity = 10**6)#Replayを実行するかどうか\n",
    "phi = lambda x:x.astype(np.float32, copy=False)##型の変換(chainerはfloat32型。float64は駄目)\n",
    "\n",
    "agent = chainerrl.agents.DoubleDQN(\n",
    "    q_func, optimizer, replay_buffer, gamma, explorer,\n",
    "    replay_start_size=500, update_interval=1,\n",
    "    target_update_interval=100, phi=phi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "n_episodes = 50\n",
    "max_episode_len = 2000\n",
    "start = time.time()\n",
    "episode_step=list()\n",
    "episode_gain=list()\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = asiya_env.reset()\n",
    "    reward = 0\n",
    "    done = False\n",
    "    R = 0  # return (sum of rewards)\n",
    "    t = 0  # time step\n",
    "    while not done and t < max_episode_len:\n",
    "        action = agent.act_and_train(obs, reward)\n",
    "        obs, reward, done, option = asiya_env.step(action)\n",
    "        R += reward\n",
    "        t += 1\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print('episode:', i,\n",
    "              'R:', R,\n",
    "              'statistics:', agent.get_statistics())\n",
    "    agent.stop_episode_and_train(obs, reward, done)\n",
    "    episode_step.append(i)\n",
    "    episode_gain.append(asiya_env.total_gain)\n",
    "    #エピソードごとの成績を作成\n",
    "    \n",
    "print('Finished, elapsed time : {}'.format(time.time()-start))\n",
    "analysis_df=pd.DataFrame()\n",
    "analysis_df['ep_step']=episode_step\n",
    "analysis_df['ep_gain']=episode_gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-warrior",
   "metadata": {},
   "source": [
    "## 成長過程をもっと可視化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name='asiya'\n",
    "#cash=100000#所持金\n",
    "cash=100000#所持金\n",
    "target_com=5\n",
    "#target_com=2\n",
    "\n",
    "result_filepath=\"../boatracer_BOT_making/bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "sample_race_df=pd.read_csv(result_filepath)\n",
    "sample_race_df=sample_race_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "sample_race_df.head()\n",
    "sample_race_df=data_making(sample_race_df)#前処理\n",
    "asiya_env =BoatraceComEnv(target_com,sample_race_df,cash)#環境の作成（クラス）\n",
    "\n",
    "#Q関数の設定\n",
    "obs_size = asiya_env.obs_size\n",
    "n_actions = asiya_env.n_action\n",
    "q_func = QFunction(obs_size, n_actions)\n",
    "q_func.to_gpu(0)\n",
    "#q_func.to_gpu(0) ## GPUを使いたい人はこのコメントを外す\n",
    "\n",
    "#最適化手法とパラメータ設定\n",
    "optimizer = chainer.optimizers.Adam(eps=1e-2)\n",
    "optimizer.setup(q_func) #設計したq関数の最適化にAdamを使う\n",
    "gamma = 0.80#報酬の割引率.過去の結果をどのくらい重要視するか\n",
    "explorer = chainerrl.explorers.ConstantEpsilonGreedy(#次の戦略を考えるときの方法\n",
    "    epsilon=0.3, random_action_func=asiya_env.random_action_func)\n",
    "replay_buffer = chainerrl.replay_buffer.ReplayBuffer(capacity = 10**6)#Replayを実行するかどうか\n",
    "phi = lambda x:x.astype(np.float32, copy=False)##型の変換(chainerはfloat32型。float64は駄目)\n",
    "\n",
    "agent = chainerrl.agents.DoubleDQN(\n",
    "    q_func, optimizer, replay_buffer, gamma, explorer,\n",
    "    replay_start_size=500, update_interval=1,\n",
    "    target_update_interval=100, phi=phi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "n_episodes = 50\n",
    "max_episode_len = 2000\n",
    "start = time.time()\n",
    "episode_step=list()\n",
    "episode_gain=list()\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = asiya_env.reset()\n",
    "    reward = 0\n",
    "    done = False\n",
    "    R = 0  # return (sum of rewards)\n",
    "    t = 0  # time step\n",
    "    while not done and t < max_episode_len:\n",
    "        action = agent.act_and_train(obs, reward)\n",
    "        obs, reward, done, option = asiya_env.step(action)\n",
    "        R += reward\n",
    "        t += 1\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print('episode:', i,\n",
    "              'R:', R,\n",
    "              'statistics:', agent.get_statistics())\n",
    "    agent.stop_episode_and_train(obs, reward, done)\n",
    "    episode_step.append(i)\n",
    "    episode_gain.append(asiya_env.total_gain)\n",
    "    #エピソードごとの成績を作成\n",
    "    \n",
    "print('Finished, elapsed time : {}'.format(time.time()-start))\n",
    "analysis_df=pd.DataFrame()\n",
    "analysis_df['ep_step']=episode_step\n",
    "analysis_df['ep_gain']=episode_gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "elementary-detroit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep_step</th>\n",
       "      <th>ep_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-25.809487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-66.960916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-40.341060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.718844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-51.125041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-2.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>-33.653782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-23.351869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-12.297432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>-23.516829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>-48.226568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>19.580897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>-46.262238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>-30.707333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.150962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>-33.893315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>-50.364360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>-28.741787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>4.838070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>-30.381398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>-26.877843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>-10.665033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>-36.925278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>-8.134052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>-20.513912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>-43.180534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>-28.180898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>-23.713995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>9.422680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>-36.579194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>-44.033758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>-46.088136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>-24.976974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>-24.273340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>-26.117144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>-57.910891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>-54.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>-20.991649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>-58.981002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>-43.576818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>-31.707481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>-58.399448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>-35.848765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>-45.568641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>-18.878893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>-53.970297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>-30.497857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>-11.822581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>-54.153024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>6.269103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ep_step    ep_gain\n",
       "0         1 -25.809487\n",
       "1         2 -66.960916\n",
       "2         3 -40.341060\n",
       "3         4  -0.718844\n",
       "4         5 -51.125041\n",
       "5         6  -2.692308\n",
       "6         7 -33.653782\n",
       "7         8 -23.351869\n",
       "8         9 -12.297432\n",
       "9        10 -23.516829\n",
       "10       11 -48.226568\n",
       "11       12  19.580897\n",
       "12       13 -46.262238\n",
       "13       14 -30.707333\n",
       "14       15   1.150962\n",
       "15       16 -33.893315\n",
       "16       17 -50.364360\n",
       "17       18 -28.741787\n",
       "18       19   4.838070\n",
       "19       20 -30.381398\n",
       "20       21 -26.877843\n",
       "21       22 -10.665033\n",
       "22       23 -36.925278\n",
       "23       24  -8.134052\n",
       "24       25 -20.513912\n",
       "25       26 -43.180534\n",
       "26       27 -28.180898\n",
       "27       28 -23.713995\n",
       "28       29   9.422680\n",
       "29       30 -36.579194\n",
       "30       31 -44.033758\n",
       "31       32 -46.088136\n",
       "32       33 -24.976974\n",
       "33       34 -24.273340\n",
       "34       35 -26.117144\n",
       "35       36 -57.910891\n",
       "36       37 -54.102564\n",
       "37       38 -20.991649\n",
       "38       39 -58.981002\n",
       "39       40 -43.576818\n",
       "40       41 -31.707481\n",
       "41       42 -58.399448\n",
       "42       43 -35.848765\n",
       "43       44 -45.568641\n",
       "44       45 -18.878893\n",
       "45       46 -53.970297\n",
       "46       47 -30.497857\n",
       "47       48 -11.822581\n",
       "48       49 -54.153024\n",
       "49       50   6.269103"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-pledge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-footage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "coral-medicare",
   "metadata": {},
   "source": [
    "# 参考リンク集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-transcription",
   "metadata": {},
   "source": [
    "・強化学習でビットコイントレードしたいかもしれないので役に立ちそうなリンクをメモしとく<br>\n",
    "https://scrapbox.io/arms22/%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92%E3%81%A7%E3%83%93%E3%83%83%E3%83%88%E3%82%B3%E3%82%A4%E3%83%B3%E3%83%88%E3%83%AC%E3%83%BC%E3%83%89%E3%81%97%E3%81%9F%E3%81%84%E3%81%8B%E3%82%82%E3%81%97%E3%82%8C%E3%81%AA%E3%81%84%E3%81%AE%E3%81%A7%E5%BD%B9%E3%81%AB%E7%AB%8B%E3%81%A1%E3%81%9D%E3%81%86%E3%81%AA%E3%83%AA%E3%83%B3%E3%82%AF%E3%82%92%E3%83%A1%E3%83%A2%E3%81%97%E3%81%A8%E3%81%8F<br>\n",
    "イラスト多めで概念の理解に助かる : https://meet.metaps.com/entry/2017/08/10/ai/<br>\n",
    "トレード，成功例  :  https://qiita.com/ryo_grid/items/ae78835f9a61d020145f<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-wallet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
